{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given: Data about the movement of empty containers in Hapag-Lloyd's system and need to analyze how efficient these movements are.   \n",
    "\n",
    "Goal: Identify where the company can improve its operations and use this analysis to create a dashboard for audits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hapag-Lloyd moves empty containers to places where they’re needed (deficit locations) from places where they’re not (surplus locations). Sometimes, these movements aren’t efficient, or the proposed movements (actions) don’t actually happen.\n",
    "\n",
    "Task: Analyze the data to answer the following questions:\n",
    "\n",
    "Surplus and Demand: Which locations have too many empty containers (surplus), and which need more (deficit)?\n",
    "Action Success: How many proposed container movements were successfully booked (used) versus canceled (not used)?\n",
    "Repeated Failures: Are there specific proposals that keep getting canceled but never executed?\n",
    "Inefficiencies:\n",
    "Circular Movements: Are containers being moved in unnecessary loops (e.g., back to where they started)?\n",
    "Indirect Routing: Are containers being sent to an unnecessary middle location before reaching their final destination?\n",
    "\n",
    "Breakdown:\n",
    "\n",
    "1. Analyze Surplus and Deficit\n",
    "Look at where containers are coming from (Subarea From) and where they’re going (Subarea To).\n",
    "Calculate the total number of containers moved from and to each location.\n",
    "Find out which locations have extra containers (surplus) and which need containers (deficit).\n",
    "2. Conversion Rate\n",
    "Compare proposed container movements (Volume TEU Proposal) with the actual movements (Volume TEU Actual).\n",
    "Calculate how many proposed movements were successfully completed (conversion rate).\n",
    "Separate the conversion rates for system-generated actions and user-generated actions.\n",
    "3. Repeatedly Canceled Proposals\n",
    "Find proposals (ID Number) that keep getting canceled.\n",
    "Count how many times a proposal appears with the status “CL” (Canceled).\n",
    "4. Inefficiencies\n",
    "Circular Movements: Check if containers of the same type go in a loop (e.g., A → B → C → A) within a short time (4 weeks).\n",
    "Indirect Routing: Check if containers are sent to an unnecessary stop before reaching their destination. For example:\n",
    "Surplus: A → B → C\n",
    "Deficit: A → C (Direct would’ve been better.) or redundancies/inefficiencies like (A → B → C → B) visiting the same location twice in a 4 week window! The timeline is the basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the needed libraries\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "from icecream import ic\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "from typing import Dict, Tuple\n",
    "from functools import lru_cache\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load/read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- cell only to be ran once ---\n",
    "\n",
    "# Path to the zip file\n",
    "zip_path = r\"C:\\Users\\adeba\\OneDrive\\Desktop\\hapag-lloyd\\Case_study_DCT_Analyst_2025.zip\" #replace file path\n",
    "\n",
    "# folder to extract the files\n",
    "extract_folder = r\"C:\\Users\\adeba\\OneDrive\\Desktop\\hapag-lloyd\" #replace file path\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "# os.makedirs(extract_folder, exist_ok=True)\n",
    "\n",
    "# Extract files\n",
    "# with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "#     z.extractall(extract_folder)\n",
    "#     ic(\"Files extracted to:\", extract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read the files directly from the extracted folder\n",
    "dap_path = os.path.join(extract_folder, \"dap.xlsx\")\n",
    "eq_type_path = os.path.join(extract_folder, \"eq_type.xlsx\")\n",
    "subarea_path = os.path.join(extract_folder, \"subarea.xlsx\")\n",
    "\n",
    "# Load the files into DataFrames\n",
    "dap_df = pd.read_excel(dap_path)\n",
    "eq_type_df = pd.read_excel(eq_type_path)\n",
    "subarea_df = pd.read_excel(subarea_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dap_df:  Index(['ID Number', 'EQ Type', 'Status', 'Source Flag', 'Subarea From',\n",
      "       'Locode From', 'Subarea To', 'Locode TO', 'Start Yearweek',\n",
      "       'End Yearweek', 'MoT', 'Volume TEU Proposal', 'Volume TEU Actual'],\n",
      "      dtype='object') eq_type_df:  Index(['EQ Type', 'EQ Type Desc'], dtype='object') subarea_df:  Index(['Region Code/Name', 'Subregion Code/Name', 'Area Code/Name',\n",
      "       'Subarea Code/Name', 'UN Locode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#to have original column names might be needed to reintegrate the data at the end\n",
    "print('dap_df: ', dap_df.columns, 'eq_type_df: ', eq_type_df.columns, 'subarea_df: ',subarea_df.columns)\n",
    "original_columns_dap =  dap_df.columns\n",
    "original_columns_eq = eq_type_df.columns\n",
    "original_columns_subarea = subarea_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Number</th>\n",
       "      <th>EQ Type</th>\n",
       "      <th>Status</th>\n",
       "      <th>Source Flag</th>\n",
       "      <th>Subarea From</th>\n",
       "      <th>Locode From</th>\n",
       "      <th>Subarea To</th>\n",
       "      <th>Locode TO</th>\n",
       "      <th>Start Yearweek</th>\n",
       "      <th>End Yearweek</th>\n",
       "      <th>MoT</th>\n",
       "      <th>Volume TEU Proposal</th>\n",
       "      <th>Volume TEU Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7852175</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNANANR</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>MINCENSA</td>\n",
       "      <td>INNSA</td>\n",
       "      <td>202401</td>\n",
       "      <td>202406</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7852174</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNANANR</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>MINSEMAA</td>\n",
       "      <td>INMAA</td>\n",
       "      <td>202401</td>\n",
       "      <td>202407</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7960411</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBSOU</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNVUT</td>\n",
       "      <td>202403</td>\n",
       "      <td>202408</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7807536</td>\n",
       "      <td>40GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBLON</td>\n",
       "      <td>GBLGP</td>\n",
       "      <td>ACNSCYTN</td>\n",
       "      <td>CNYTN</td>\n",
       "      <td>202404</td>\n",
       "      <td>202409</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7851816</td>\n",
       "      <td>40GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBSOU</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNVUT</td>\n",
       "      <td>202404</td>\n",
       "      <td>202409</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475981</th>\n",
       "      <td>8584842</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202447</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475982</th>\n",
       "      <td>8630606</td>\n",
       "      <td>40RE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>AJPJPHKT</td>\n",
       "      <td>JPHKT</td>\n",
       "      <td>LPEECGYE</td>\n",
       "      <td>ECGYE</td>\n",
       "      <td>202440</td>\n",
       "      <td>202447</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475983</th>\n",
       "      <td>8603364</td>\n",
       "      <td>40RE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>AJPJPSMZ</td>\n",
       "      <td>JPSMZ</td>\n",
       "      <td>LPEECGYE</td>\n",
       "      <td>ECGYE</td>\n",
       "      <td>202440</td>\n",
       "      <td>202447</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475984</th>\n",
       "      <td>8627378</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>LCAGTPBR</td>\n",
       "      <td>GTPBR</td>\n",
       "      <td>LBRRGRIG</td>\n",
       "      <td>BRRIG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202448</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475985</th>\n",
       "      <td>8627377</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>LCAGTPBR</td>\n",
       "      <td>GTPBR</td>\n",
       "      <td>LBRSCNVT</td>\n",
       "      <td>BRNVT</td>\n",
       "      <td>202440</td>\n",
       "      <td>202448</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475986 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Number EQ Type Status Source Flag Subarea From Locode From  \\\n",
       "0         7852175    20GE     BK           U     EBNANANR       BEANR   \n",
       "1         7852174    20GE     BK           U     EBNANANR       BEANR   \n",
       "2         7960411    40HC     BK           U     EBIGBSOU       GBSOU   \n",
       "3         7807536    40GE     CL           U     EBIGBLON       GBLGP   \n",
       "4         7851816    40GE     BK           U     EBIGBSOU       GBSOU   \n",
       "...           ...     ...    ...         ...          ...         ...   \n",
       "475981    8584842    40HC     BK           U     MASZACPT       ZACPT   \n",
       "475982    8630606    40RE     BK           U     AJPJPHKT       JPHKT   \n",
       "475983    8603364    40RE     BK           U     AJPJPSMZ       JPSMZ   \n",
       "475984    8627378    20GE     BK           U     LCAGTPBR       GTPBR   \n",
       "475985    8627377    40HC     BK           U     LCAGTPBR       GTPBR   \n",
       "\n",
       "       Subarea To Locode TO  Start Yearweek  End Yearweek MoT  \\\n",
       "0        MINCENSA     INNSA          202401        202406  VE   \n",
       "1        MINSEMAA     INMAA          202401        202407  VE   \n",
       "2        AICVNSGN     VNVUT          202403        202408  VE   \n",
       "3        ACNSCYTN     CNYTN          202404        202409  VE   \n",
       "4        AICVNSGN     VNVUT          202404        202409  VE   \n",
       "...           ...       ...             ...           ...  ..   \n",
       "475981   LBRPRPNG     BRPNG          202440        202447  MX   \n",
       "475982   LPEECGYE     ECGYE          202440        202447  VE   \n",
       "475983   LPEECGYE     ECGYE          202440        202447  VE   \n",
       "475984   LBRRGRIG     BRRIG          202440        202448  MX   \n",
       "475985   LBRSCNVT     BRNVT          202440        202448  MX   \n",
       "\n",
       "        Volume TEU Proposal  Volume TEU Actual  \n",
       "0                         0                 50  \n",
       "1                         0                 11  \n",
       "2                         0                  4  \n",
       "3                         0                  0  \n",
       "4                         0                  6  \n",
       "...                     ...                ...  \n",
       "475981                    0                 12  \n",
       "475982                    0                 40  \n",
       "475983                    0                  4  \n",
       "475984                    0                 50  \n",
       "475985                    0                100  \n",
       "\n",
       "[475986 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EQ Type</th>\n",
       "      <th>EQ Type Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20FL</td>\n",
       "      <td>20' Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20FL</td>\n",
       "      <td>40' Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20GE</td>\n",
       "      <td>20' General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20HT</td>\n",
       "      <td>20' Hard Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20OT</td>\n",
       "      <td>20' Open Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20RC</td>\n",
       "      <td>20' Reefer Non-foodgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20RE</td>\n",
       "      <td>20' Reefer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20TK</td>\n",
       "      <td>20' Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20VE</td>\n",
       "      <td>20' Ventilated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40FL</td>\n",
       "      <td>40' Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40GE</td>\n",
       "      <td>40' General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40GE</td>\n",
       "      <td>40'General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40HC</td>\n",
       "      <td>40' High Cube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40HC</td>\n",
       "      <td>40'High Cube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40HT</td>\n",
       "      <td>40' Hard Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40OT</td>\n",
       "      <td>40' Open Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>40RC</td>\n",
       "      <td>40' Reefer Non-foodgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40RE</td>\n",
       "      <td>40' Reefer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40TK</td>\n",
       "      <td>40' Tank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>45EQ</td>\n",
       "      <td>45' General High Cube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>n/r</td>\n",
       "      <td>Not relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EQ Type              EQ Type Desc\n",
       "0     20FL                  20' Flat\n",
       "1     20FL                  40' Flat\n",
       "2     20GE               20' General\n",
       "3     20HT              20' Hard Top\n",
       "4     20OT              20' Open Top\n",
       "5     20RC  20' Reefer Non-foodgrade\n",
       "6     20RE                20' Reefer\n",
       "7     20TK                  20' Tank\n",
       "8     20VE            20' Ventilated\n",
       "9     40FL                  40' Flat\n",
       "10    40GE               40' General\n",
       "11    40GE                40'General\n",
       "12    40HC             40' High Cube\n",
       "13    40HC              40'High Cube\n",
       "14    40HT              40' Hard Top\n",
       "15    40OT              40' Open Top\n",
       "16    40RC  40' Reefer Non-foodgrade\n",
       "17    40RE                40' Reefer\n",
       "18    40TK                  40' Tank\n",
       "19    45EQ     45' General High Cube\n",
       "20     NaN             Not available\n",
       "21     n/r              Not relevant"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region Code/Name</th>\n",
       "      <th>Subregion Code/Name</th>\n",
       "      <th>Area Code/Name</th>\n",
       "      <th>Subarea Code/Name</th>\n",
       "      <th>UN Locode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S / S. EUROPE</td>\n",
       "      <td>SIB / IBERIA</td>\n",
       "      <td>SIBEM / SP MED</td>\n",
       "      <td>SIBEMBCN / BARCELONA</td>\n",
       "      <td>ADALV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAUH / ABU DHABI</td>\n",
       "      <td>AEAAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAJM / AJMAN</td>\n",
       "      <td>AEAJM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEJEA / JEBEL ALI</td>\n",
       "      <td>AEALQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAUH / ABU DHABI</td>\n",
       "      <td>AEAUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16710</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAS / S. AFRICA</td>\n",
       "      <td>MASZA / S. AFRICA</td>\n",
       "      <td>MASZAHRE / HARARE</td>\n",
       "      <td>ZWVFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16711</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAS / S. AFRICA</td>\n",
       "      <td>MASZA / S. AFRICA</td>\n",
       "      <td>MASZAHRE / HARARE</td>\n",
       "      <td>ZWWKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16712</th>\n",
       "      <td>? / n/a</td>\n",
       "      <td>??? / n/a</td>\n",
       "      <td>????? / n/a</td>\n",
       "      <td>???????? / n/a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16713</th>\n",
       "      <td>! / n/r</td>\n",
       "      <td>!!! / n/r</td>\n",
       "      <td>!!!!! / n/r</td>\n",
       "      <td>!!!!!!!! / n/r</td>\n",
       "      <td>n/r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>* / n/u</td>\n",
       "      <td>*** / n/u</td>\n",
       "      <td>***** / n/u</td>\n",
       "      <td>******** / n/u</td>\n",
       "      <td>n/u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16715 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Region Code/Name Subregion Code/Name     Area Code/Name  \\\n",
       "0        S / S. EUROPE        SIB / IBERIA     SIBEM / SP MED   \n",
       "1          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "2          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "3          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "4          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "...                ...                 ...                ...   \n",
       "16710      M / M. EAST     MAS / S. AFRICA  MASZA / S. AFRICA   \n",
       "16711      M / M. EAST     MAS / S. AFRICA  MASZA / S. AFRICA   \n",
       "16712          ? / n/a           ??? / n/a        ????? / n/a   \n",
       "16713          ! / n/r           !!! / n/r        !!!!! / n/r   \n",
       "16714          * / n/u           *** / n/u        ***** / n/u   \n",
       "\n",
       "          Subarea Code/Name UN Locode  \n",
       "0      SIBEMBCN / BARCELONA     ADALV  \n",
       "1      MAGAEAUH / ABU DHABI     AEAAN  \n",
       "2          MAGAEAJM / AJMAN     AEAJM  \n",
       "3      MAGAEJEA / JEBEL ALI     AEALQ  \n",
       "4      MAGAEAUH / ABU DHABI     AEAUH  \n",
       "...                     ...       ...  \n",
       "16710     MASZAHRE / HARARE     ZWVFA  \n",
       "16711     MASZAHRE / HARARE     ZWWKI  \n",
       "16712        ???????? / n/a       NaN  \n",
       "16713        !!!!!!!! / n/r       n/r  \n",
       "16714        ******** / n/u       n/u  \n",
       "\n",
       "[16715 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#quick overview of what I am dealing with\n",
    "display(dap_df, eq_type_df, subarea_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing and cleaning\n",
    "#### 2.1. clean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    # Convert to lowercase and replace spaces with underscores\n",
    "    df.columns = [x.lower().replace(' ', '_') for x in list(df.columns)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in preprocessing\n",
    "dap_cleaned = clean_column_names(dap_df)\n",
    "eq_type_cleaned = clean_column_names(eq_type_df)\n",
    "subarea_cleaned = clean_column_names(subarea_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate IDs: 230266\n",
      "Duplicate IDs found! Displaying the rows for investigation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20090</th>\n",
       "      <td>7790397</td>\n",
       "      <td>20FL</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNSCGGZ</td>\n",
       "      <td>CNHUA</td>\n",
       "      <td>ACNSCSHK</td>\n",
       "      <td>CNSHK</td>\n",
       "      <td>202401</td>\n",
       "      <td>202401</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20091</th>\n",
       "      <td>7792648</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNSCHKG</td>\n",
       "      <td>HKHKG</td>\n",
       "      <td>ACNSCZSN</td>\n",
       "      <td>CNSUD</td>\n",
       "      <td>202402</td>\n",
       "      <td>202402</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20092</th>\n",
       "      <td>7808128</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNSCGGZ</td>\n",
       "      <td>CNHUA</td>\n",
       "      <td>ACNSCGGZ</td>\n",
       "      <td>CNGOM</td>\n",
       "      <td>202402</td>\n",
       "      <td>202402</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20093</th>\n",
       "      <td>7792674</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>AKRRURUS</td>\n",
       "      <td>RUVVO</td>\n",
       "      <td>AKRKRPUS</td>\n",
       "      <td>KRPUS</td>\n",
       "      <td>202401</td>\n",
       "      <td>202402</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20094</th>\n",
       "      <td>7791820</td>\n",
       "      <td>40GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNSCZSN</td>\n",
       "      <td>CNXIN</td>\n",
       "      <td>ACNSCZSN</td>\n",
       "      <td>CNJMN</td>\n",
       "      <td>202402</td>\n",
       "      <td>202402</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475980</th>\n",
       "      <td>8664949</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>LCAHNPCR</td>\n",
       "      <td>HNPCR</td>\n",
       "      <td>LBRRGRIG</td>\n",
       "      <td>BRRIG</td>\n",
       "      <td>202439</td>\n",
       "      <td>202447</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475982</th>\n",
       "      <td>8630606</td>\n",
       "      <td>40RE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>AJPJPHKT</td>\n",
       "      <td>JPHKT</td>\n",
       "      <td>LPEECGYE</td>\n",
       "      <td>ECGYE</td>\n",
       "      <td>202440</td>\n",
       "      <td>202447</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475983</th>\n",
       "      <td>8603364</td>\n",
       "      <td>40RE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>AJPJPSMZ</td>\n",
       "      <td>JPSMZ</td>\n",
       "      <td>LPEECGYE</td>\n",
       "      <td>ECGYE</td>\n",
       "      <td>202440</td>\n",
       "      <td>202447</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475984</th>\n",
       "      <td>8627378</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>LCAGTPBR</td>\n",
       "      <td>GTPBR</td>\n",
       "      <td>LBRRGRIG</td>\n",
       "      <td>BRRIG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202448</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475985</th>\n",
       "      <td>8627377</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>LCAGTPBR</td>\n",
       "      <td>GTPBR</td>\n",
       "      <td>LBRSCNVT</td>\n",
       "      <td>BRNVT</td>\n",
       "      <td>202440</td>\n",
       "      <td>202448</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230266 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "20090     7790397    20FL     BK           U     ACNSCGGZ       CNHUA   \n",
       "20091     7792648    20GE     CL           U     ACNSCHKG       HKHKG   \n",
       "20092     7808128    20GE     BK           U     ACNSCGGZ       CNHUA   \n",
       "20093     7792674    20GE     BK           U     AKRRURUS       RUVVO   \n",
       "20094     7791820    40GE     BK           U     ACNSCZSN       CNXIN   \n",
       "...           ...     ...    ...         ...          ...         ...   \n",
       "475980    8664949    20GE     BK           U     LCAHNPCR       HNPCR   \n",
       "475982    8630606    40RE     BK           U     AJPJPHKT       JPHKT   \n",
       "475983    8603364    40RE     BK           U     AJPJPSMZ       JPSMZ   \n",
       "475984    8627378    20GE     BK           U     LCAGTPBR       GTPBR   \n",
       "475985    8627377    40HC     BK           U     LCAGTPBR       GTPBR   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek mot  \\\n",
       "20090    ACNSCSHK     CNSHK          202401        202401  VE   \n",
       "20091    ACNSCZSN     CNSUD          202402        202402  VE   \n",
       "20092    ACNSCGGZ     CNGOM          202402        202402  VE   \n",
       "20093    AKRKRPUS     KRPUS          202401        202402  VE   \n",
       "20094    ACNSCZSN     CNJMN          202402        202402  VE   \n",
       "...           ...       ...             ...           ...  ..   \n",
       "475980   LBRRGRIG     BRRIG          202439        202447  MX   \n",
       "475982   LPEECGYE     ECGYE          202440        202447  VE   \n",
       "475983   LPEECGYE     ECGYE          202440        202447  VE   \n",
       "475984   LBRRGRIG     BRRIG          202440        202448  MX   \n",
       "475985   LBRSCNVT     BRNVT          202440        202448  MX   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "20090                     0                  3  \n",
       "20091                     0                  0  \n",
       "20092                     0                 50  \n",
       "20093                     0                  1  \n",
       "20094                     0                  2  \n",
       "...                     ...                ...  \n",
       "475980                    0                 78  \n",
       "475982                    0                 40  \n",
       "475983                    0                  4  \n",
       "475984                    0                 50  \n",
       "475985                    0                100  \n",
       "\n",
       "[230266 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Why Check for Duplicate IDs?\n",
    "\n",
    "\"\"\"\n",
    "The `ID Number` column is described as a unique identifier for action proposals in the dataset. \n",
    "This means each ID should correspond to exactly one proposal. \n",
    "Duplicate IDs could indicate potential data issues, such as errors in the data ingestion process or \n",
    "overlapping proposals. Identifying and addressing these duplicates is critical to ensuring the \n",
    "integrity of our analysis.\n",
    "\n",
    "For example:\n",
    "- If duplicates exist, it could lead to double-counting proposals in metrics like total container volumes.\n",
    "- Erroneous duplicates might mask inefficiencies in the DAP system or skew decision-making insights.\n",
    "\n",
    "Therefore, checking for duplicate `ID Number`s is a necessary quality assurance step in preparing the data for analysis.\n",
    "\"\"\"\n",
    "\n",
    "# Code: Check for Duplicate IDs\n",
    "duplicate_ids = dap_cleaned[dap_cleaned.duplicated(subset=[\"id_number\"])]\n",
    "print(f\"Number of duplicate IDs: {duplicate_ids.shape[0]}\")\n",
    "\n",
    "if not duplicate_ids.empty:\n",
    "    print(\"Duplicate IDs found! Displaying the rows for investigation:\")\n",
    "    display(duplicate_ids)\n",
    "else:\n",
    "    print(\"No duplicate IDs found. The dataset is clean in this regard.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 check for exact duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exact_duplicates(df, unique_id_column):\n",
    "    \"\"\"\n",
    "    Function to check for duplicates based on a unique ID column and verify identical values across all columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame to check for duplicates\n",
    "    - unique_id_column: The column that should uniquely identify each row\n",
    "    \n",
    "    Returns:\n",
    "    - duplicates_with_discrepancies: Rows where the same ID has different values in other columns\n",
    "    - exact_duplicates: True duplicates with identical values in all columns\n",
    "    \"\"\"\n",
    "    # Identify duplicate IDs\n",
    "    duplicate_rows = df[df.duplicated(subset=[unique_id_column], keep=False)]\n",
    "    \n",
    "    # Group duplicates by the unique ID and check for discrepancies\n",
    "    # Efficient comparison by transforming the group into a single sorted string for each group\n",
    "    grouped = duplicate_rows.groupby(unique_id_column)\n",
    "    discrepancies = grouped.filter(\n",
    "        lambda group: len(group.drop_duplicates()) > 1\n",
    "    )\n",
    "    \n",
    "    # Exact duplicates can be determined once\n",
    "    exact_duplicates = duplicate_rows.drop_duplicates()\n",
    "    \n",
    "    return discrepancies, exact_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates with discrepancies found. All duplicates are exact matches.\n",
      "Number of exact duplicates: 230266\n"
     ]
    }
   ],
   "source": [
    "# checking for discrepancies in the duplicates, rows must match 1:1\n",
    "duplicates_with_discrepancies, exact_duplicates = check_exact_duplicates(dap_cleaned, unique_id_column=\"id_number\")\n",
    "\n",
    "# Display results\n",
    "if not duplicates_with_discrepancies.empty:\n",
    "    print(\"Duplicates with discrepancies found! These need further investigation:\")\n",
    "    display(duplicates_with_discrepancies)\n",
    "else:\n",
    "    print(\"No duplicates with discrepancies found. All duplicates are exact matches.\")\n",
    "\n",
    "print(f\"Number of exact duplicates: {exact_duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 remove (exact) duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7852175</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNANANR</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>MINCENSA</td>\n",
       "      <td>INNSA</td>\n",
       "      <td>202401</td>\n",
       "      <td>202406</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7852174</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNANANR</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>MINSEMAA</td>\n",
       "      <td>INMAA</td>\n",
       "      <td>202401</td>\n",
       "      <td>202407</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7960411</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBSOU</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNVUT</td>\n",
       "      <td>202403</td>\n",
       "      <td>202408</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7807536</td>\n",
       "      <td>40GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBLON</td>\n",
       "      <td>GBLGP</td>\n",
       "      <td>ACNSCYTN</td>\n",
       "      <td>CNYTN</td>\n",
       "      <td>202404</td>\n",
       "      <td>202409</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7851816</td>\n",
       "      <td>40GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBSOU</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNVUT</td>\n",
       "      <td>202404</td>\n",
       "      <td>202409</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475966</th>\n",
       "      <td>8601399</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZADUR</td>\n",
       "      <td>ZADUR</td>\n",
       "      <td>LBRSCITJ</td>\n",
       "      <td>BRITJ</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475967</th>\n",
       "      <td>8601455</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZADUR</td>\n",
       "      <td>ZADUR</td>\n",
       "      <td>LBRSCITJ</td>\n",
       "      <td>BRITJ</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475968</th>\n",
       "      <td>8568371</td>\n",
       "      <td>20OT</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>LBRSCITJ</td>\n",
       "      <td>BRITJ</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475978</th>\n",
       "      <td>8575159</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475981</th>\n",
       "      <td>8584842</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202447</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245720 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "0         7852175    20GE     BK           U     EBNANANR       BEANR   \n",
       "1         7852174    20GE     BK           U     EBNANANR       BEANR   \n",
       "2         7960411    40HC     BK           U     EBIGBSOU       GBSOU   \n",
       "3         7807536    40GE     CL           U     EBIGBLON       GBLGP   \n",
       "4         7851816    40GE     BK           U     EBIGBSOU       GBSOU   \n",
       "...           ...     ...    ...         ...          ...         ...   \n",
       "475966    8601399    20OT     CL           U     MASZADUR       ZADUR   \n",
       "475967    8601455    20OT     CL           U     MASZADUR       ZADUR   \n",
       "475968    8568371    20OT     BK           U     MASZACPT       ZACPT   \n",
       "475978    8575159    40HC     BK           U     MASZACPT       ZACPT   \n",
       "475981    8584842    40HC     BK           U     MASZACPT       ZACPT   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek mot  \\\n",
       "0        MINCENSA     INNSA          202401        202406  VE   \n",
       "1        MINSEMAA     INMAA          202401        202407  VE   \n",
       "2        AICVNSGN     VNVUT          202403        202408  VE   \n",
       "3        ACNSCYTN     CNYTN          202404        202409  VE   \n",
       "4        AICVNSGN     VNVUT          202404        202409  VE   \n",
       "...           ...       ...             ...           ...  ..   \n",
       "475966   LBRSCITJ     BRITJ          202440        202446  MX   \n",
       "475967   LBRSCITJ     BRITJ          202440        202446  MX   \n",
       "475968   LBRSCITJ     BRITJ          202440        202446  MX   \n",
       "475978   LBRPRPNG     BRPNG          202440        202446  MX   \n",
       "475981   LBRPRPNG     BRPNG          202440        202447  MX   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "0                         0                 50  \n",
       "1                         0                 11  \n",
       "2                         0                  4  \n",
       "3                         0                  0  \n",
       "4                         0                  6  \n",
       "...                     ...                ...  \n",
       "475966                    0                  0  \n",
       "475967                    0                  0  \n",
       "475968                    0                  2  \n",
       "475978                    0                 36  \n",
       "475981                    0                 12  \n",
       "\n",
       "[245720 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can now safely drop duplicates\n",
    "dap_cleaned = dap_cleaned.drop_duplicates()\n",
    "dap_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_code/name</th>\n",
       "      <th>subregion_code/name</th>\n",
       "      <th>area_code/name</th>\n",
       "      <th>subarea_code/name</th>\n",
       "      <th>un_locode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S / S. EUROPE</td>\n",
       "      <td>SIB / IBERIA</td>\n",
       "      <td>SIBEM / SP MED</td>\n",
       "      <td>SIBEMBCN / BARCELONA</td>\n",
       "      <td>ADALV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAUH / ABU DHABI</td>\n",
       "      <td>AEAAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAJM / AJMAN</td>\n",
       "      <td>AEAJM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEJEA / JEBEL ALI</td>\n",
       "      <td>AEALQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAUH / ABU DHABI</td>\n",
       "      <td>AEAUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16710</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAS / S. AFRICA</td>\n",
       "      <td>MASZA / S. AFRICA</td>\n",
       "      <td>MASZAHRE / HARARE</td>\n",
       "      <td>ZWVFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16711</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAS / S. AFRICA</td>\n",
       "      <td>MASZA / S. AFRICA</td>\n",
       "      <td>MASZAHRE / HARARE</td>\n",
       "      <td>ZWWKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16712</th>\n",
       "      <td>? / n/a</td>\n",
       "      <td>??? / n/a</td>\n",
       "      <td>????? / n/a</td>\n",
       "      <td>???????? / n/a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16713</th>\n",
       "      <td>! / n/r</td>\n",
       "      <td>!!! / n/r</td>\n",
       "      <td>!!!!! / n/r</td>\n",
       "      <td>!!!!!!!! / n/r</td>\n",
       "      <td>n/r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>* / n/u</td>\n",
       "      <td>*** / n/u</td>\n",
       "      <td>***** / n/u</td>\n",
       "      <td>******** / n/u</td>\n",
       "      <td>n/u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16715 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      region_code/name subregion_code/name     area_code/name  \\\n",
       "0        S / S. EUROPE        SIB / IBERIA     SIBEM / SP MED   \n",
       "1          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "2          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "3          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "4          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "...                ...                 ...                ...   \n",
       "16710      M / M. EAST     MAS / S. AFRICA  MASZA / S. AFRICA   \n",
       "16711      M / M. EAST     MAS / S. AFRICA  MASZA / S. AFRICA   \n",
       "16712          ? / n/a           ??? / n/a        ????? / n/a   \n",
       "16713          ! / n/r           !!! / n/r        !!!!! / n/r   \n",
       "16714          * / n/u           *** / n/u        ***** / n/u   \n",
       "\n",
       "          subarea_code/name un_locode  \n",
       "0      SIBEMBCN / BARCELONA     ADALV  \n",
       "1      MAGAEAUH / ABU DHABI     AEAAN  \n",
       "2          MAGAEAJM / AJMAN     AEAJM  \n",
       "3      MAGAEJEA / JEBEL ALI     AEALQ  \n",
       "4      MAGAEAUH / ABU DHABI     AEAUH  \n",
       "...                     ...       ...  \n",
       "16710     MASZAHRE / HARARE     ZWVFA  \n",
       "16711     MASZAHRE / HARARE     ZWWKI  \n",
       "16712        ???????? / n/a       NaN  \n",
       "16713        !!!!!!!! / n/r       n/r  \n",
       "16714        ******** / n/u       n/u  \n",
       "\n",
       "[16715 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subarea_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Validation\n",
    "#### 3.1 Validate Locations in the DAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No UN locodes have multiple subarea parents\n"
     ]
    }
   ],
   "source": [
    "#check if a locode can have more than one sobarea parent\n",
    "def check_locode_multiple_subareas(df):\n",
    "       # Count unique subarea codes per UN locode\n",
    "   locode_analysis = df.groupby('un_locode')['subarea_code/name'].agg(['nunique', 'unique'])\n",
    "   \n",
    "   # Filter for UN locodes with multiple subareas\n",
    "   multiple_subareas = locode_analysis[locode_analysis['nunique'] > 1]\n",
    "   \n",
    "   if len(multiple_subareas) > 0:\n",
    "       print(f\"Found {len(multiple_subareas)} UN locodes with multiple subareas:\")\n",
    "       for locode, row in multiple_subareas.iterrows():\n",
    "           print(f\"\\nUN Locode: {locode}\")\n",
    "           print(f\"Subareas: {row['unique']}\")\n",
    "   else:\n",
    "       print(\"No UN locodes have multiple subarea parents\")\n",
    "       \n",
    "   return multiple_subareas\n",
    "\n",
    "# Run analysis\n",
    "duplicates = check_locode_multiple_subareas(subarea_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_locations(dap_df, subarea_df):\n",
    "       # Extract unique values and master data\n",
    "   dap_subareas_from = set(dap_df['subarea_from'].unique())\n",
    "   dap_subareas_to = set(dap_df['subarea_to'].unique())\n",
    "   dap_locodes_from = set(dap_df['locode_from'].unique())\n",
    "   dap_locodes_to = set(dap_df['locode_to'].unique())\n",
    "\n",
    "   master_subareas = set(subarea_df['subarea_code/name'].str.split('/').str[0].str.strip().unique())\n",
    "   master_locodes = set(subarea_df['un_locode'].str.strip().unique())\n",
    "\n",
    "   # Find invalid values\n",
    "   invalid = {\n",
    "       'invalid_subareas_from': dap_subareas_from - master_subareas,\n",
    "       'invalid_subareas_to': dap_subareas_to - master_subareas,\n",
    "       'invalid_locodes_from': dap_locodes_from - master_locodes,\n",
    "       'invalid_locodes_to': dap_locodes_to - master_locodes\n",
    "   }\n",
    "\n",
    "   # Create invalid data frame from original data\n",
    "   invalid_dap = dap_df[\n",
    "       (dap_df['subarea_from'].isin(invalid['invalid_subareas_from'])) |\n",
    "       (dap_df['subarea_to'].isin(invalid['invalid_subareas_to'])) |\n",
    "       (dap_df['locode_from'].isin(invalid['invalid_locodes_from'])) |\n",
    "       (dap_df['locode_to'].isin(invalid['invalid_locodes_to']))\n",
    "   ]\n",
    "\n",
    "   # Create valid data frame\n",
    "   valid_dap = dap_df[\n",
    "       ~(dap_df['subarea_from'].isin(invalid['invalid_subareas_from'])) &\n",
    "       ~(dap_df['subarea_to'].isin(invalid['invalid_subareas_to'])) &\n",
    "       ~(dap_df['locode_from'].isin(invalid['invalid_locodes_from'])) &\n",
    "       ~(dap_df['locode_to'].isin(invalid['invalid_locodes_to']))\n",
    "   ]\n",
    "\n",
    "   return invalid, invalid_dap, valid_dap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 245720\n",
      "Invalid rows: 3621\n",
      "Valid rows: 242099\n"
     ]
    }
   ],
   "source": [
    "# extract rows with unindentified location (not present in the subarea_df) from the dap data\n",
    "invalid_values, unidentified_locations, dap_with_location = validate_locations(dap_cleaned, subarea_cleaned)\n",
    "print(f\"Total rows: {len(dap_cleaned)}\")\n",
    "print(f\"Invalid rows: {len(unidentified_locations)}\")\n",
    "print(f\"Valid rows: {len(dap_with_location)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in valid locations: 0\n",
      "Duplicates in invalid locations: 0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates in the new dap data and the unidentified locations dataframe\n",
    "def check_duplicates(dap_with_location, unidentified_locations):\n",
    "       # Check duplicates in valid locations\n",
    "   valid_dupes = dap_with_location[dap_with_location.duplicated(subset=['id_number'], keep=False)]\n",
    "   \n",
    "   # Check duplicates in invalid locations\n",
    "   invalid_dupes = unidentified_locations[unidentified_locations.duplicated(subset=['id_number'], keep=False)]\n",
    "   \n",
    "   print(f\"Duplicates in valid locations: {len(valid_dupes)}\")\n",
    "   print(f\"Duplicates in invalid locations: {len(invalid_dupes)}\")\n",
    "   \n",
    "   return valid_dupes, invalid_dupes\n",
    "\n",
    "valid_duplicates, invalid_duplicates = check_duplicates(dap_with_location, unidentified_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>7828978</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENOFIHEL</td>\n",
       "      <td>FIHEL</td>\n",
       "      <td>202403</td>\n",
       "      <td>202404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7801745</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENOFIKOK</td>\n",
       "      <td>FIKOK</td>\n",
       "      <td>202402</td>\n",
       "      <td>202403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7769091</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EGEFFFRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202402</td>\n",
       "      <td>202403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7774708</td>\n",
       "      <td>40GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EGCFFFRA</td>\n",
       "      <td>DEFRA</td>\n",
       "      <td>202403</td>\n",
       "      <td>202404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7791908</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EGCSTSTR</td>\n",
       "      <td>DEWOE</td>\n",
       "      <td>202403</td>\n",
       "      <td>202404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466472</th>\n",
       "      <td>8538791</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBNRTRTM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>202438</td>\n",
       "      <td>202440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466474</th>\n",
       "      <td>8538805</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBNRTRTM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>202439</td>\n",
       "      <td>202441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466475</th>\n",
       "      <td>8538191</td>\n",
       "      <td>40OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBNRTRTM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>202439</td>\n",
       "      <td>202441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466476</th>\n",
       "      <td>8549254</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBNANANR</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>202438</td>\n",
       "      <td>202440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466480</th>\n",
       "      <td>8550326</td>\n",
       "      <td>40OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EGCHAHAM</td>\n",
       "      <td>DEHAM</td>\n",
       "      <td>202438</td>\n",
       "      <td>202440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3621 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "83        7828978    40FL     CL           U          EBN         NaN   \n",
       "111       7801745    20GE     CL           U          EGE         NaN   \n",
       "144       7769091    40HC     CL           U          EBN         NaN   \n",
       "145       7774708    40GE     CL           U          EBN         NaN   \n",
       "146       7791908    40HC     CL           U          EBN         NaN   \n",
       "...           ...     ...    ...         ...          ...         ...   \n",
       "466472    8538791    40FL     CL           U            M         NaN   \n",
       "466474    8538805    40FL     CL           U            M         NaN   \n",
       "466475    8538191    40OT     CL           U            M         NaN   \n",
       "466476    8549254    40FL     CL           U            M         NaN   \n",
       "466480    8550326    40OT     CL           U            M         NaN   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek  mot  \\\n",
       "83       ENOFIHEL     FIHEL          202403        202404  NaN   \n",
       "111      ENOFIKOK     FIKOK          202402        202403  NaN   \n",
       "144      EGEFFFRA       NaN          202402        202403  NaN   \n",
       "145      EGCFFFRA     DEFRA          202403        202404  NaN   \n",
       "146      EGCSTSTR     DEWOE          202403        202404  NaN   \n",
       "...           ...       ...             ...           ...  ...   \n",
       "466472   EBNRTRTM     NLRTM          202438        202440  NaN   \n",
       "466474   EBNRTRTM     NLRTM          202439        202441  NaN   \n",
       "466475   EBNRTRTM     NLRTM          202439        202441  NaN   \n",
       "466476   EBNANANR     BEANR          202438        202440  NaN   \n",
       "466480   EGCHAHAM     DEHAM          202438        202440  NaN   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "83                       16                  0  \n",
       "111                      30                  0  \n",
       "144                      40                  0  \n",
       "145                      40                  0  \n",
       "146                      80                  0  \n",
       "...                     ...                ...  \n",
       "466472                   30                  0  \n",
       "466474                   30                  0  \n",
       "466475                   30                  0  \n",
       "466476                   36                  0  \n",
       "466480                   40                  0  \n",
       "\n",
       "[3621 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidentified_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| unidentified_locations['status'].unique(): array(['CL', 'BK'], dtype=object)\n",
      "ic| unidentified_locations['source_flag'].unique(): array(['U'], dtype=object)\n",
      "ic| unidentified_locations['volume_teu_actual'].unique(): array([  0,   5,   2, 100,  56,   8,  48, 200,   1,  50, 140, 112,  60,\n",
      "                                                                  34,  26,  46,   6,  40,  80,  68, 116, 120,   3,   4,  18,  12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   5,   2, 100,  56,   8,  48, 200,   1,  50, 140, 112,  60,\n",
       "        34,  26,  46,   6,  40,  80,  68, 116, 120,   3,   4,  18,  12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from eyeballing the dataframe, it seems unidentified locations data has the source_flag 'U'\n",
    "ic(unidentified_locations['status'].unique())\n",
    "ic(unidentified_locations['source_flag'].unique())\n",
    "ic(unidentified_locations['volume_teu_actual'].unique())\n",
    "\n",
    "#conclusion, unidentified locations data were all user generated. WHY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#digging deeper with the unidentified locations\n",
    "unidentified_locations[unidentified_locations[['locode_from', 'locode_to']].isna().all(axis=1)]['volume_teu_actual'].unique()\n",
    "#also situations where unidentified locations dataframe has a missing locode, the Volume TEU Actual is 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Validate equipment type in the DAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_equipment_types(dap_df, eq_type_df):\n",
    "       # Extract unique equipment types\n",
    "   dap_eq_types = set(dap_df['eq_type'].unique())\n",
    "   master_eq_types = set(eq_type_df['eq_type'].unique())\n",
    "   \n",
    "   # Find invalid equipment types\n",
    "   invalid_eq_types = dap_eq_types - master_eq_types\n",
    "   \n",
    "   # Create dataframes for valid and invalid records\n",
    "   invalid_eq_data = dap_df[dap_df['eq_type'].isin(invalid_eq_types)]\n",
    "   valid_eq_data = dap_df[~dap_df['eq_type'].isin(invalid_eq_types)]\n",
    "   \n",
    "   return {\n",
    "       'invalid_types': invalid_eq_types,\n",
    "       'invalid_data': invalid_eq_data,\n",
    "       'valid_data': valid_eq_data\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 242099\n",
      "Invalid equipment types: set()\n",
      "Records with invalid equipment: 0\n",
      "Records with valid equipment: 242099\n"
     ]
    }
   ],
   "source": [
    "# check dap equipments in the equipments master data\n",
    "eq_validation = validate_equipment_types(dap_with_location, eq_type_cleaned)\n",
    "print(f\"Total records: {len(dap_with_location)}\")\n",
    "print(f\"Invalid equipment types: {eq_validation['invalid_types']}\")\n",
    "print(f\"Records with invalid equipment: {len(eq_validation['invalid_data'])}\")\n",
    "print(f\"Records with valid equipment: {len(eq_validation['valid_data'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Check for and handle missing values in the DAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_number                 0\n",
      "eq_type                   0\n",
      "status                    0\n",
      "source_flag               0\n",
      "subarea_from              0\n",
      "locode_from              62\n",
      "subarea_to                0\n",
      "locode_to                59\n",
      "start_yearweek            0\n",
      "end_yearweek              0\n",
      "mot                    4286\n",
      "volume_teu_proposal       0\n",
      "volume_teu_actual         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dap_with_location.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>7827890</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202403</td>\n",
       "      <td>202404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9706</th>\n",
       "      <td>7849924</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202404</td>\n",
       "      <td>202405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>7849925</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202404</td>\n",
       "      <td>202405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47938</th>\n",
       "      <td>7872040</td>\n",
       "      <td>40OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AANAUADL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>SGSIN</td>\n",
       "      <td>202405</td>\n",
       "      <td>202407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47944</th>\n",
       "      <td>7933760</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AANAUMEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>SGSIN</td>\n",
       "      <td>202408</td>\n",
       "      <td>202409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399853</th>\n",
       "      <td>8537691</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCTAO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202436</td>\n",
       "      <td>202437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399855</th>\n",
       "      <td>8457537</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCNGB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202434</td>\n",
       "      <td>202435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404393</th>\n",
       "      <td>8485728</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCOCOBAQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCOCOCTG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202435</td>\n",
       "      <td>202435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404826</th>\n",
       "      <td>8511621</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUSCU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUSCU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202436</td>\n",
       "      <td>202437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431423</th>\n",
       "      <td>8511881</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LARUYMVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202438</td>\n",
       "      <td>202440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "9704      7827890    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "9706      7849924    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "9747      7849925    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "47938     7872040    40OT     CL           U     AANAUADL         NaN   \n",
       "47944     7933760    40HC     CL           U     AANAUMEL         NaN   \n",
       "...           ...     ...    ...         ...          ...         ...   \n",
       "399853    8537691    20GE     CL           U     ACNNCTAG         NaN   \n",
       "399855    8457537    40HC     CL           U     ACNNCTAG         NaN   \n",
       "404393    8485728    20GE     CL           U     LCOCOBAQ         NaN   \n",
       "404826    8511621    20OT     CL           U     LCLCUSCU         NaN   \n",
       "431423    8511881    20GE     CL           U     ASASGSIN         NaN   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek  mot  \\\n",
       "9704     LCLCUMAR       NaN          202403        202404  NaN   \n",
       "9706     LCLCUMAR       NaN          202404        202405  NaN   \n",
       "9747     LCLCUMAR       NaN          202404        202405  NaN   \n",
       "47938    ASASGSIN     SGSIN          202405        202407  NaN   \n",
       "47944    ASASGSIN     SGSIN          202408        202409  NaN   \n",
       "...           ...       ...             ...           ...  ...   \n",
       "399853   ACNNCTAO       NaN          202436        202437  NaN   \n",
       "399855   ACNNCNGB       NaN          202434        202435  NaN   \n",
       "404393   LCOCOCTG       NaN          202435        202435  NaN   \n",
       "404826   LCLCUSCU       NaN          202436        202437  NaN   \n",
       "431423   LARUYMVD       NaN          202438        202440  NaN   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "9704                      2                  0  \n",
       "9706                      2                  0  \n",
       "9747                     10                  0  \n",
       "47938                    20                  0  \n",
       "47944                    54                  0  \n",
       "...                     ...                ...  \n",
       "399853                  500                  0  \n",
       "399855                 2000                  0  \n",
       "404393                   50                  0  \n",
       "404826                    1                  0  \n",
       "431423                   15                  0  \n",
       "\n",
       "[62 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>7827890</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202403</td>\n",
       "      <td>202404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9706</th>\n",
       "      <td>7849924</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202404</td>\n",
       "      <td>202405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>7849925</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202404</td>\n",
       "      <td>202405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48196</th>\n",
       "      <td>7871343</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNDAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202405</td>\n",
       "      <td>202406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52722</th>\n",
       "      <td>7876495</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCADOCAU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SITITLIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202408</td>\n",
       "      <td>202410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52723</th>\n",
       "      <td>7880773</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCADOCAU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SITITGOA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202407</td>\n",
       "      <td>202410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53126</th>\n",
       "      <td>7872469</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLPAPUQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLSOLQN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202406</td>\n",
       "      <td>202407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53127</th>\n",
       "      <td>7871669</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLNOANF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLSOLQN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202406</td>\n",
       "      <td>202406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53134</th>\n",
       "      <td>7871811</td>\n",
       "      <td>40GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLNOPAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLNOANF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202405</td>\n",
       "      <td>202405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56927</th>\n",
       "      <td>7874948</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EGCHAHAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SITITGOA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202407</td>\n",
       "      <td>202411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92795</th>\n",
       "      <td>7977896</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411</td>\n",
       "      <td>202411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92806</th>\n",
       "      <td>7990693</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411</td>\n",
       "      <td>202411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96613</th>\n",
       "      <td>7995416</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCOCOBUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LPEECGYE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202412</td>\n",
       "      <td>202413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97096</th>\n",
       "      <td>7960800</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202410</td>\n",
       "      <td>202411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97113</th>\n",
       "      <td>7960799</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202410</td>\n",
       "      <td>202411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97138</th>\n",
       "      <td>7995021</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411</td>\n",
       "      <td>202412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97197</th>\n",
       "      <td>7959555</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LPEECGYE</td>\n",
       "      <td>ECGYE</td>\n",
       "      <td>LCLNOANF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202410</td>\n",
       "      <td>202411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101141</th>\n",
       "      <td>7959467</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>SMABSNVS</td>\n",
       "      <td>RUNVS</td>\n",
       "      <td>STRTRGEM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202409</td>\n",
       "      <td>202410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110836</th>\n",
       "      <td>7993926</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIIEDUB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBIIEBEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411</td>\n",
       "      <td>202412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110837</th>\n",
       "      <td>7993927</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIIEDUB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBIIEBEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202412</td>\n",
       "      <td>202413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110883</th>\n",
       "      <td>7995117</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNRTRTM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>EGCATWAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202412</td>\n",
       "      <td>202412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149530</th>\n",
       "      <td>7990777</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIIEDUB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBIIEBEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202413</td>\n",
       "      <td>202414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154880</th>\n",
       "      <td>8020611</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LPEPECLL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCESAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202413</td>\n",
       "      <td>202414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155020</th>\n",
       "      <td>8043580</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202414</td>\n",
       "      <td>202415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155042</th>\n",
       "      <td>8060060</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202414</td>\n",
       "      <td>202415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155046</th>\n",
       "      <td>8078262</td>\n",
       "      <td>20RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202415</td>\n",
       "      <td>202416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155071</th>\n",
       "      <td>8078688</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLPAPUQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLSOLQN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202416</td>\n",
       "      <td>202417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202621</th>\n",
       "      <td>8111438</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202417</td>\n",
       "      <td>202418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209303</th>\n",
       "      <td>8131522</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>SMABSPTI</td>\n",
       "      <td>GEPTI</td>\n",
       "      <td>STRGRPIR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202419</td>\n",
       "      <td>202419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229710</th>\n",
       "      <td>8188652</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202421</td>\n",
       "      <td>202422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229715</th>\n",
       "      <td>8205260</td>\n",
       "      <td>45EQ</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUMAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202423</td>\n",
       "      <td>202424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253756</th>\n",
       "      <td>8174520</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ASAMYPKG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202421</td>\n",
       "      <td>202422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253757</th>\n",
       "      <td>8224678</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AANAUSYD</td>\n",
       "      <td>AUSYD</td>\n",
       "      <td>ASAMYPKG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202424</td>\n",
       "      <td>202424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254037</th>\n",
       "      <td>8191200</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCWHI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202422</td>\n",
       "      <td>202423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254038</th>\n",
       "      <td>8191199</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCWUH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202422</td>\n",
       "      <td>202423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254049</th>\n",
       "      <td>8224777</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCNGB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202424</td>\n",
       "      <td>202424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254050</th>\n",
       "      <td>8191032</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCNKG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202422</td>\n",
       "      <td>202423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254117</th>\n",
       "      <td>8241406</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNDAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202424</td>\n",
       "      <td>202425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254118</th>\n",
       "      <td>8241342</td>\n",
       "      <td>20RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNDAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202424</td>\n",
       "      <td>202425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254120</th>\n",
       "      <td>8241420</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNDAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202424</td>\n",
       "      <td>202425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254121</th>\n",
       "      <td>8241421</td>\n",
       "      <td>40HT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNDAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202424</td>\n",
       "      <td>202425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284213</th>\n",
       "      <td>8243357</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCNGB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202425</td>\n",
       "      <td>202425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284214</th>\n",
       "      <td>8285865</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCNGB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202427</td>\n",
       "      <td>202427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303414</th>\n",
       "      <td>8281038</td>\n",
       "      <td>20RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLNOANF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCESAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202427</td>\n",
       "      <td>202427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317956</th>\n",
       "      <td>8329717</td>\n",
       "      <td>40OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>SMANAALG</td>\n",
       "      <td>DZSKI</td>\n",
       "      <td>STRTRIZM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202429</td>\n",
       "      <td>202430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330527</th>\n",
       "      <td>8321790</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>NNECHCHI</td>\n",
       "      <td>USCHI</td>\n",
       "      <td>NCAVAPRR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202428</td>\n",
       "      <td>202429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350938</th>\n",
       "      <td>8405960</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCNGB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202432</td>\n",
       "      <td>202432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351072</th>\n",
       "      <td>8349464</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ASAMYKCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASAMYPKG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202430</td>\n",
       "      <td>202430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390864</th>\n",
       "      <td>8426849</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MINWEMUN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NSESASAV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202434</td>\n",
       "      <td>202437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390866</th>\n",
       "      <td>8429174</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MINLKCMB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNSCYTN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202434</td>\n",
       "      <td>202436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399447</th>\n",
       "      <td>8511898</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCSHA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLSOLQN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202436</td>\n",
       "      <td>202437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399500</th>\n",
       "      <td>8457479</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNSCYTN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202434</td>\n",
       "      <td>202436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399853</th>\n",
       "      <td>8537691</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCTAO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202436</td>\n",
       "      <td>202437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399855</th>\n",
       "      <td>8457537</td>\n",
       "      <td>40HC</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ACNNCTAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACNNCNGB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202434</td>\n",
       "      <td>202435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404393</th>\n",
       "      <td>8485728</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCOCOBAQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCOCOCTG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202435</td>\n",
       "      <td>202435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404826</th>\n",
       "      <td>8511621</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>LCLCUSCU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LCLCUSCU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202436</td>\n",
       "      <td>202437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419165</th>\n",
       "      <td>8485402</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>SMABSPTI</td>\n",
       "      <td>GEPTI</td>\n",
       "      <td>STRGRPIR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202435</td>\n",
       "      <td>202435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431423</th>\n",
       "      <td>8511881</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ASASGSIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LARUYMVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202438</td>\n",
       "      <td>202440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456707</th>\n",
       "      <td>8539530</td>\n",
       "      <td>40OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>SMABSPTI</td>\n",
       "      <td>GEPTI</td>\n",
       "      <td>STRTRIST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202437</td>\n",
       "      <td>202437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "9704      7827890    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "9706      7849924    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "9747      7849925    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "48196     7871343    40FL     CL           U     AICVNDAD         NaN   \n",
       "52722     7876495    40HC     CL           U     LCADOCAU         NaN   \n",
       "52723     7880773    40HC     CL           U     LCADOCAU         NaN   \n",
       "53126     7872469    20GE     CL           U     LCLPAPUQ         NaN   \n",
       "53127     7871669    40RE     CL           U     LCLNOANF         NaN   \n",
       "53134     7871811    40GE     CL           U     LCLNOPAG         NaN   \n",
       "56927     7874948    20GE     CL           U     EGCHAHAM         NaN   \n",
       "92795     7977896    40FL     CL           U     AICVNSGN         NaN   \n",
       "92806     7990693    40FL     CL           U     AICVNSGN         NaN   \n",
       "96613     7995416    40RE     CL           U     LCOCOBUN         NaN   \n",
       "97096     7960800    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "97113     7960799    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "97138     7995021    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "97197     7959555    40HC     CL           U     LPEECGYE       ECGYE   \n",
       "101141    7959467    40RE     CL           U     SMABSNVS       RUNVS   \n",
       "110836    7993926    40HC     CL           U     EBIIEDUB         NaN   \n",
       "110837    7993927    40HC     CL           U     EBIIEDUB         NaN   \n",
       "110883    7995117    40HC     CL           U     EBNRTRTM       NLRTM   \n",
       "149530    7990777    40HC     CL           U     EBIIEDUB         NaN   \n",
       "154880    8020611    40RE     CL           U     LPEPECLL         NaN   \n",
       "155020    8043580    20GE     CL           U     LCLCUMAR         NaN   \n",
       "155042    8060060    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "155046    8078262    20RE     CL           U     LCLCUMAR         NaN   \n",
       "155071    8078688    20GE     CL           U     LCLPAPUQ         NaN   \n",
       "202621    8111438    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "209303    8131522    40RE     CL           U     SMABSPTI       GEPTI   \n",
       "229710    8188652    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "229715    8205260    45EQ     CL           U     LCLCUMAR         NaN   \n",
       "253756    8174520    40RE     CL           U     ASAMYPKG         NaN   \n",
       "253757    8224678    20GE     CL           U     AANAUSYD       AUSYD   \n",
       "254037    8191200    40HC     CL           U     ACNNCTAG         NaN   \n",
       "254038    8191199    40HC     CL           U     ACNNCTAG         NaN   \n",
       "254049    8224777    20GE     CL           U     ACNNCTAG         NaN   \n",
       "254050    8191032    40HC     CL           U     ACNNCTAG         NaN   \n",
       "254117    8241406    20OT     CL           U     AICVNDAD         NaN   \n",
       "254118    8241342    20RE     CL           U     AICVNDAD         NaN   \n",
       "254120    8241420    20OT     CL           U     AICVNDAD         NaN   \n",
       "254121    8241421    40HT     CL           U     AICVNDAD         NaN   \n",
       "284213    8243357    20GE     CL           U     ACNNCTAG         NaN   \n",
       "284214    8285865    20GE     CL           U     ACNNCTAG         NaN   \n",
       "303414    8281038    20RE     CL           U     LCLNOANF         NaN   \n",
       "317956    8329717    40OT     CL           U     SMANAALG       DZSKI   \n",
       "330527    8321790    20GE     CL           U     NNECHCHI       USCHI   \n",
       "350938    8405960    40HC     CL           U     ACNNCTAG         NaN   \n",
       "351072    8349464    20GE     CL           U     ASAMYKCH         NaN   \n",
       "390864    8426849    40FL     CL           U     MINWEMUN         NaN   \n",
       "390866    8429174    40HC     CL           U     MINLKCMB         NaN   \n",
       "399447    8511898    40RE     CL           U     ACNNCSHA         NaN   \n",
       "399500    8457479    40HC     CL           U     ASASGSIN         NaN   \n",
       "399853    8537691    20GE     CL           U     ACNNCTAG         NaN   \n",
       "399855    8457537    40HC     CL           U     ACNNCTAG         NaN   \n",
       "404393    8485728    20GE     CL           U     LCOCOBAQ         NaN   \n",
       "404826    8511621    20OT     CL           U     LCLCUSCU         NaN   \n",
       "419165    8485402    20GE     CL           U     SMABSPTI       GEPTI   \n",
       "431423    8511881    20GE     CL           U     ASASGSIN         NaN   \n",
       "456707    8539530    40OT     CL           U     SMABSPTI       GEPTI   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek  mot  \\\n",
       "9704     LCLCUMAR       NaN          202403        202404  NaN   \n",
       "9706     LCLCUMAR       NaN          202404        202405  NaN   \n",
       "9747     LCLCUMAR       NaN          202404        202405  NaN   \n",
       "48196    ASASGSIN       NaN          202405        202406  NaN   \n",
       "52722    SITITLIV       NaN          202408        202410  NaN   \n",
       "52723    SITITGOA       NaN          202407        202410  NaN   \n",
       "53126    LCLSOLQN       NaN          202406        202407  NaN   \n",
       "53127    LCLSOLQN       NaN          202406        202406  NaN   \n",
       "53134    LCLNOANF       NaN          202405        202405  NaN   \n",
       "56927    SITITGOA       NaN          202407        202411  NaN   \n",
       "92795    ASASGSIN       NaN          202411        202411  NaN   \n",
       "92806    ASASGSIN       NaN          202411        202411  NaN   \n",
       "96613    LPEECGYE       NaN          202412        202413  NaN   \n",
       "97096    LCLCUMAR       NaN          202410        202411  NaN   \n",
       "97113    LCLCUMAR       NaN          202410        202411  NaN   \n",
       "97138    LCLCUMAR       NaN          202411        202412  NaN   \n",
       "97197    LCLNOANF       NaN          202410        202411  NaN   \n",
       "101141   STRTRGEM       NaN          202409        202410  NaN   \n",
       "110836   EBIIEBEL       NaN          202411        202412  NaN   \n",
       "110837   EBIIEBEL       NaN          202412        202413  NaN   \n",
       "110883   EGCATWAT       NaN          202412        202412  NaN   \n",
       "149530   EBIIEBEL       NaN          202413        202414  NaN   \n",
       "154880   LCLCESAI       NaN          202413        202414  NaN   \n",
       "155020   LCLCUMAR       NaN          202414        202415  NaN   \n",
       "155042   LCLCUMAR       NaN          202414        202415  NaN   \n",
       "155046   LCLCUMAR       NaN          202415        202416  NaN   \n",
       "155071   LCLSOLQN       NaN          202416        202417  NaN   \n",
       "202621   LCLCUMAR       NaN          202417        202418  NaN   \n",
       "209303   STRGRPIR       NaN          202419        202419  NaN   \n",
       "229710   LCLCUMAR       NaN          202421        202422  NaN   \n",
       "229715   LCLCUMAR       NaN          202423        202424  NaN   \n",
       "253756   ASASGSIN       NaN          202421        202422  NaN   \n",
       "253757   ASAMYPKG       NaN          202424        202424  NaN   \n",
       "254037   ACNNCWHI       NaN          202422        202423  NaN   \n",
       "254038   ACNNCWUH       NaN          202422        202423  NaN   \n",
       "254049   ACNNCNGB       NaN          202424        202424  NaN   \n",
       "254050   ACNNCNKG       NaN          202422        202423  NaN   \n",
       "254117   ASASGSIN       NaN          202424        202425  NaN   \n",
       "254118   ASASGSIN       NaN          202424        202425  NaN   \n",
       "254120   ASASGSIN       NaN          202424        202425  NaN   \n",
       "254121   ASASGSIN       NaN          202424        202425  NaN   \n",
       "284213   ACNNCNGB       NaN          202425        202425  NaN   \n",
       "284214   ACNNCNGB       NaN          202427        202427  NaN   \n",
       "303414   LCLCESAI       NaN          202427        202427  NaN   \n",
       "317956   STRTRIZM       NaN          202429        202430  NaN   \n",
       "330527   NCAVAPRR       NaN          202428        202429  NaN   \n",
       "350938   ACNNCNGB       NaN          202432        202432  NaN   \n",
       "351072   ASAMYPKG       NaN          202430        202430  NaN   \n",
       "390864   NSESASAV       NaN          202434        202437  NaN   \n",
       "390866   ACNSCYTN       NaN          202434        202436  NaN   \n",
       "399447   LCLSOLQN       NaN          202436        202437  NaN   \n",
       "399500   ACNSCYTN       NaN          202434        202436  NaN   \n",
       "399853   ACNNCTAO       NaN          202436        202437  NaN   \n",
       "399855   ACNNCNGB       NaN          202434        202435  NaN   \n",
       "404393   LCOCOCTG       NaN          202435        202435  NaN   \n",
       "404826   LCLCUSCU       NaN          202436        202437  NaN   \n",
       "419165   STRGRPIR       NaN          202435        202435  NaN   \n",
       "431423   LARUYMVD       NaN          202438        202440  NaN   \n",
       "456707   STRTRIST       NaN          202437        202437  NaN   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "9704                      2                  0  \n",
       "9706                      2                  0  \n",
       "9747                     10                  0  \n",
       "48196                     2                  0  \n",
       "52722                   352                  0  \n",
       "52723                   496                  0  \n",
       "53126                     1                  0  \n",
       "53127                    12                  0  \n",
       "53134                     2                  0  \n",
       "56927                   100                  0  \n",
       "92795                    30                  0  \n",
       "92806                    28                  0  \n",
       "96613                   200                  0  \n",
       "97096                     2                  0  \n",
       "97113                     6                  0  \n",
       "97138                    20                  0  \n",
       "97197                   200                  0  \n",
       "101141                   10                  0  \n",
       "110836                   38                  0  \n",
       "110837                   38                  0  \n",
       "110883                   40                  0  \n",
       "149530                   38                  0  \n",
       "154880                   60                  0  \n",
       "155020                    1                  0  \n",
       "155042                    4                  0  \n",
       "155046                    3                  0  \n",
       "155071                   10                  0  \n",
       "202621                    2                  0  \n",
       "209303                    2                  0  \n",
       "229710                    2                  0  \n",
       "229715                    2                  0  \n",
       "253756                   84                  0  \n",
       "253757                   50                  0  \n",
       "254037                  200                  0  \n",
       "254038                  200                  0  \n",
       "254049                  300                  0  \n",
       "254050                  600                  0  \n",
       "254117                    1                  0  \n",
       "254118                    1                  0  \n",
       "254120                    2                  0  \n",
       "254121                    4                  0  \n",
       "284213                  300                  0  \n",
       "284214                  300                  0  \n",
       "303414                   14                  0  \n",
       "317956                    2                  0  \n",
       "330527                   50                  0  \n",
       "350938                  260                  0  \n",
       "351072                    1                  0  \n",
       "390864                   40                  0  \n",
       "390866                 1560                  0  \n",
       "399447                  100                  0  \n",
       "399500                 1000                  0  \n",
       "399853                  500                  0  \n",
       "399855                 2000                  0  \n",
       "404393                   50                  0  \n",
       "404826                    1                  0  \n",
       "419165                   30                  0  \n",
       "431423                   15                  0  \n",
       "456707                   10                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7756418</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNRTRTM</td>\n",
       "      <td>NLRTM</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>202403</td>\n",
       "      <td>202407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7808047</td>\n",
       "      <td>40FL</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EGCHAHAM</td>\n",
       "      <td>DEHAM</td>\n",
       "      <td>ENOFIRAU</td>\n",
       "      <td>FIRAU</td>\n",
       "      <td>202402</td>\n",
       "      <td>202403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7767837</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>ENOPLGDY</td>\n",
       "      <td>PLGDY</td>\n",
       "      <td>ENOFIRAU</td>\n",
       "      <td>FIRAU</td>\n",
       "      <td>202401</td>\n",
       "      <td>202402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7831040</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EGCHAHAM</td>\n",
       "      <td>DEHAM</td>\n",
       "      <td>ENOFIOUL</td>\n",
       "      <td>FIOUL</td>\n",
       "      <td>202404</td>\n",
       "      <td>202405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7828188</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EGCHAHAM</td>\n",
       "      <td>DEHAM</td>\n",
       "      <td>ENOPLGDY</td>\n",
       "      <td>PLGDY</td>\n",
       "      <td>202403</td>\n",
       "      <td>202404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471868</th>\n",
       "      <td>8476684</td>\n",
       "      <td>20GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MAWAOLAD</td>\n",
       "      <td>AOLAD</td>\n",
       "      <td>LBRSCITJ</td>\n",
       "      <td>BRITJ</td>\n",
       "      <td>202438</td>\n",
       "      <td>202440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471919</th>\n",
       "      <td>8548107</td>\n",
       "      <td>40GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MAWAOLAD</td>\n",
       "      <td>AOLAD</td>\n",
       "      <td>LBRSZSSZ</td>\n",
       "      <td>BRSSZ</td>\n",
       "      <td>202437</td>\n",
       "      <td>202439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473477</th>\n",
       "      <td>8552640</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>S</td>\n",
       "      <td>MAWAOLAD</td>\n",
       "      <td>AOLAD</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202438</td>\n",
       "      <td>202440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473692</th>\n",
       "      <td>8552928</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>S</td>\n",
       "      <td>MASZADUR</td>\n",
       "      <td>ZADUR</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202439</td>\n",
       "      <td>202443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473693</th>\n",
       "      <td>8552826</td>\n",
       "      <td>40RE</td>\n",
       "      <td>CL</td>\n",
       "      <td>S</td>\n",
       "      <td>MASZADUR</td>\n",
       "      <td>ZADUR</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4286 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "14        7756418    40RE     CL           U     EBNRTRTM       NLRTM   \n",
       "21        7808047    40FL     CL           U     EGCHAHAM       DEHAM   \n",
       "22        7767837    20GE     CL           U     ENOPLGDY       PLGDY   \n",
       "23        7831040    20GE     CL           U     EGCHAHAM       DEHAM   \n",
       "24        7828188    40RE     CL           U     EGCHAHAM       DEHAM   \n",
       "...           ...     ...    ...         ...          ...         ...   \n",
       "471868    8476684    20GE     CL           U     MAWAOLAD       AOLAD   \n",
       "471919    8548107    40GE     CL           U     MAWAOLAD       AOLAD   \n",
       "473477    8552640    40RE     CL           S     MAWAOLAD       AOLAD   \n",
       "473692    8552928    40RE     CL           S     MASZADUR       ZADUR   \n",
       "473693    8552826    40RE     CL           S     MASZADUR       ZADUR   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek  mot  \\\n",
       "14       MASZACPT     ZACPT          202403        202407  NaN   \n",
       "21       ENOFIRAU     FIRAU          202402        202403  NaN   \n",
       "22       ENOFIRAU     FIRAU          202401        202402  NaN   \n",
       "23       ENOFIOUL     FIOUL          202404        202405  NaN   \n",
       "24       ENOPLGDY     PLGDY          202403        202404  NaN   \n",
       "...           ...       ...             ...           ...  ...   \n",
       "471868   LBRSCITJ     BRITJ          202438        202440  NaN   \n",
       "471919   LBRSZSSZ     BRSSZ          202437        202439  NaN   \n",
       "473477   LBRPRPNG     BRPNG          202438        202440  NaN   \n",
       "473692   LBRPRPNG     BRPNG          202439        202443  NaN   \n",
       "473693   LBRPRPNG     BRPNG          202440        202444  NaN   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "14                       20                  0  \n",
       "21                       16                  0  \n",
       "22                       30                  0  \n",
       "23                       30                  0  \n",
       "24                       60                  0  \n",
       "...                     ...                ...  \n",
       "471868                   10                  0  \n",
       "471919                   22                  0  \n",
       "473477                   20                  0  \n",
       "473692                    4                  0  \n",
       "473693                   40                  0  \n",
       "\n",
       "[4286 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dap_with_location[dap_with_location['locode_from'].isna()], dap_with_location[dap_with_location['locode_to'].isna()], dap_with_location[dap_with_location['mot'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap_with_location[['locode_from', 'locode_to']] = dap_with_location[['locode_from', 'locode_to']].fillna('missing_locode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap_with_location[['mot']] = dap_with_location[['mot']].fillna('missing_mot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Validate timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid start yearweeks: []\n",
      "Invalid end yearweeks: [303012 320246]\n"
     ]
    }
   ],
   "source": [
    "def is_valid_yearweek(yearweek):\n",
    "    try:\n",
    "        year = int(str(yearweek)[:4])\n",
    "        week = int(str(yearweek)[4:])\n",
    "        return 1900 <= year <= 2100 and 1 <= week <= 53\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "invalid_starts = dap_with_location[~dap_with_location['start_yearweek'].apply(is_valid_yearweek)]\n",
    "invalid_ends = dap_with_location[~dap_with_location['end_yearweek'].apply(is_valid_yearweek)]\n",
    "\n",
    "print(\"Invalid start yearweeks:\", invalid_starts['start_yearweek'].unique())\n",
    "print(\"Invalid end yearweeks:\", invalid_ends['end_yearweek'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158625</th>\n",
       "      <td>8044125</td>\n",
       "      <td>40GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>LBRSZSSZ</td>\n",
       "      <td>BRSSZ</td>\n",
       "      <td>LBRSZSSZ</td>\n",
       "      <td>BRSSZ</td>\n",
       "      <td>202413</td>\n",
       "      <td>303012</td>\n",
       "      <td>TR</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289044</th>\n",
       "      <td>8305447</td>\n",
       "      <td>40RE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNSGN</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNVUT</td>\n",
       "      <td>202427</td>\n",
       "      <td>320246</td>\n",
       "      <td>WW</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "158625    8044125    40GE     BK           U     LBRSZSSZ       BRSSZ   \n",
       "289044    8305447    40RE     BK           U     AICVNSGN       VNSGN   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek mot  \\\n",
       "158625   LBRSZSSZ     BRSSZ          202413        303012  TR   \n",
       "289044   AICVNSGN     VNVUT          202427        320246  WW   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "158625                    0                  4  \n",
       "289044                    0                196  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_timelines =  [303012, 320246]\n",
    "dap_with_location[dap_with_location[['start_yearweek', 'end_yearweek']].isin(empty_timelines).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dap_with_location = dap_with_location[~dap_with_location[['start_yearweek', 'end_yearweek']].isin(empty_timelines).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>status</th>\n",
       "      <th>source_flag</th>\n",
       "      <th>subarea_from</th>\n",
       "      <th>locode_from</th>\n",
       "      <th>subarea_to</th>\n",
       "      <th>locode_to</th>\n",
       "      <th>start_yearweek</th>\n",
       "      <th>end_yearweek</th>\n",
       "      <th>mot</th>\n",
       "      <th>volume_teu_proposal</th>\n",
       "      <th>volume_teu_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7852175</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNANANR</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>MINCENSA</td>\n",
       "      <td>INNSA</td>\n",
       "      <td>202401</td>\n",
       "      <td>202406</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7852174</td>\n",
       "      <td>20GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBNANANR</td>\n",
       "      <td>BEANR</td>\n",
       "      <td>MINSEMAA</td>\n",
       "      <td>INMAA</td>\n",
       "      <td>202401</td>\n",
       "      <td>202407</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7960411</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBSOU</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNVUT</td>\n",
       "      <td>202403</td>\n",
       "      <td>202408</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7807536</td>\n",
       "      <td>40GE</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBLON</td>\n",
       "      <td>GBLGP</td>\n",
       "      <td>ACNSCYTN</td>\n",
       "      <td>CNYTN</td>\n",
       "      <td>202404</td>\n",
       "      <td>202409</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7851816</td>\n",
       "      <td>40GE</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>EBIGBSOU</td>\n",
       "      <td>GBSOU</td>\n",
       "      <td>AICVNSGN</td>\n",
       "      <td>VNVUT</td>\n",
       "      <td>202404</td>\n",
       "      <td>202409</td>\n",
       "      <td>VE</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475966</th>\n",
       "      <td>8601399</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZADUR</td>\n",
       "      <td>ZADUR</td>\n",
       "      <td>LBRSCITJ</td>\n",
       "      <td>BRITJ</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475967</th>\n",
       "      <td>8601455</td>\n",
       "      <td>20OT</td>\n",
       "      <td>CL</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZADUR</td>\n",
       "      <td>ZADUR</td>\n",
       "      <td>LBRSCITJ</td>\n",
       "      <td>BRITJ</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475968</th>\n",
       "      <td>8568371</td>\n",
       "      <td>20OT</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>LBRSCITJ</td>\n",
       "      <td>BRITJ</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475978</th>\n",
       "      <td>8575159</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202446</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475981</th>\n",
       "      <td>8584842</td>\n",
       "      <td>40HC</td>\n",
       "      <td>BK</td>\n",
       "      <td>U</td>\n",
       "      <td>MASZACPT</td>\n",
       "      <td>ZACPT</td>\n",
       "      <td>LBRPRPNG</td>\n",
       "      <td>BRPNG</td>\n",
       "      <td>202440</td>\n",
       "      <td>202447</td>\n",
       "      <td>MX</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242097 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_number eq_type status source_flag subarea_from locode_from  \\\n",
       "0         7852175    20GE     BK           U     EBNANANR       BEANR   \n",
       "1         7852174    20GE     BK           U     EBNANANR       BEANR   \n",
       "2         7960411    40HC     BK           U     EBIGBSOU       GBSOU   \n",
       "3         7807536    40GE     CL           U     EBIGBLON       GBLGP   \n",
       "4         7851816    40GE     BK           U     EBIGBSOU       GBSOU   \n",
       "...           ...     ...    ...         ...          ...         ...   \n",
       "475966    8601399    20OT     CL           U     MASZADUR       ZADUR   \n",
       "475967    8601455    20OT     CL           U     MASZADUR       ZADUR   \n",
       "475968    8568371    20OT     BK           U     MASZACPT       ZACPT   \n",
       "475978    8575159    40HC     BK           U     MASZACPT       ZACPT   \n",
       "475981    8584842    40HC     BK           U     MASZACPT       ZACPT   \n",
       "\n",
       "       subarea_to locode_to  start_yearweek  end_yearweek mot  \\\n",
       "0        MINCENSA     INNSA          202401        202406  VE   \n",
       "1        MINSEMAA     INMAA          202401        202407  VE   \n",
       "2        AICVNSGN     VNVUT          202403        202408  VE   \n",
       "3        ACNSCYTN     CNYTN          202404        202409  VE   \n",
       "4        AICVNSGN     VNVUT          202404        202409  VE   \n",
       "...           ...       ...             ...           ...  ..   \n",
       "475966   LBRSCITJ     BRITJ          202440        202446  MX   \n",
       "475967   LBRSCITJ     BRITJ          202440        202446  MX   \n",
       "475968   LBRSCITJ     BRITJ          202440        202446  MX   \n",
       "475978   LBRPRPNG     BRPNG          202440        202446  MX   \n",
       "475981   LBRPRPNG     BRPNG          202440        202447  MX   \n",
       "\n",
       "        volume_teu_proposal  volume_teu_actual  \n",
       "0                         0                 50  \n",
       "1                         0                 11  \n",
       "2                         0                  4  \n",
       "3                         0                  0  \n",
       "4                         0                  6  \n",
       "...                     ...                ...  \n",
       "475966                    0                  0  \n",
       "475967                    0                  0  \n",
       "475968                    0                  2  \n",
       "475978                    0                 36  \n",
       "475981                    0                 12  \n",
       "\n",
       "[242097 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dap_with_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned & valid data\n",
    "# #dap_with_location.to_csv(r\"C:\\Users\\adeba\\Desktop\\hapag-lloyd\\cleaned_hplld_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_number', 'eq_type', 'status', 'source_flag', 'subarea_from',\n",
       "       'locode_from', 'subarea_to', 'locode_to', 'start_yearweek',\n",
       "       'end_yearweek', 'mot', 'volume_teu_proposal', 'volume_teu_actual'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dap_with_location.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "part 1:\n",
    "1. Flow Analysis:\n",
    "\n",
    "\n",
    "* Analyze equipment flows between locations\n",
    "* Calculates net surplus/deficit for each location\n",
    "* Identifies dominant equipment flows\n",
    "\n",
    "\n",
    "2. Conversion Rate Analysis:\n",
    "\n",
    "\n",
    "* Calculates conversion rates (actual/proposed volume) for both system and user-generated actions\n",
    "* Breaks down performance by source type\n",
    "\n",
    "\n",
    "3. Inefficiency Analysis:\n",
    "\n",
    "\n",
    "* Identifies unused actions (proposed but never materialized)\n",
    "\n",
    "part 2:\n",
    "* Detects circular movements within 4-week periods\n",
    "* Finds routing inefficiencies where indirect routes are used instead of available direct routes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the function to improve performance when repeatedly converting yearweek values\n",
    "@lru_cache(maxsize=1024)\n",
    "\n",
    "\n",
    "def yearweek_to_date(yearweek: int) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Convert a yearweek integer (e.g., 202401) into a pandas Timestamp.\n",
    "    \n",
    "    Args:\n",
    "        yearweek (int): YearWeek format (YYYYWW).\n",
    "        \n",
    "    Returns:\n",
    "        pd.Timestamp: Corresponding start-of-week datetime.\n",
    "    \"\"\"\n",
    "    year = int(str(yearweek)[:4])  # Extract the year (first 4 digits)\n",
    "    week = int(str(yearweek)[4:])  # Extract the week number (last 2 digits)\n",
    "    return pd.to_datetime(f\"{year}-W{week:02d}-1\", format=\"%Y-W%W-%w\")\n",
    "\n",
    "\n",
    "def preprocess_dataframe(\n",
    "    df: pd.DataFrame, min_volume: float, include_cancelled: bool, location_type: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the input DataFrame by filtering and adding derived columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input container movement DataFrame.\n",
    "        min_volume (float): Minimum volume threshold for filtering.\n",
    "        include_cancelled (bool): Whether to include cancelled movements.\n",
    "        location_type (str): Location type ('locode' or 'subarea') to determine columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame with additional calculated fields.\n",
    "    \"\"\"\n",
    "    # Dynamically determine the location columns based on location_type\n",
    "    location_from = f\"{location_type}_from\"\n",
    "    location_to = f\"{location_type}_to\"\n",
    "\n",
    "    # Retain only necessary columns to optimize memory usage and computation\n",
    "    needed_columns = [\n",
    "        'status', 'volume_teu_proposal', 'volume_teu_actual',\n",
    "        'start_yearweek', 'end_yearweek', location_from,\n",
    "        location_to, 'eq_type', 'source_flag', 'mot'\n",
    "    ]\n",
    "    df = df[needed_columns].copy()  # Make a copy of the required columns\n",
    "\n",
    "    # Apply filtering based on volume and cancellation status\n",
    "    mask = (df['volume_teu_proposal'] >= min_volume)  # Filter by minimum volume\n",
    "    if not include_cancelled:\n",
    "        mask &= (df['status'] != 'CL')  # Exclude cancelled movements if specified\n",
    "    df = df[mask]\n",
    "\n",
    "    # Add derived columns for start and end dates based on yearweek\n",
    "    df['start_date'] = df['start_yearweek'].apply(yearweek_to_date)\n",
    "    df['end_date'] = df['end_yearweek'].apply(yearweek_to_date)\n",
    "\n",
    "    # Calculate the duration of each movement in weeks\n",
    "    df['duration_weeks'] = (df['end_date'] - df['start_date']).dt.days / 7\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def analyze_flows(df: pd.DataFrame, location_type: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Analyze container flows between locations and calculate inflow/outflow stats.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Preprocessed DataFrame with movement data.\n",
    "        location_type (str): Location type ('locode' or 'subarea') to determine columns.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: \n",
    "            - Aggregated flows between locations.\n",
    "            - Location-level inflow, outflow, and net flow statistics.\n",
    "    \"\"\"\n",
    "    # Dynamically determine the location columns based on location_type\n",
    "    location_from = f\"{location_type}_from\"\n",
    "    location_to = f\"{location_type}_to\"\n",
    "\n",
    "    # Calculate total proposed volume for each flow (grouped by location pair and equipment type)\n",
    "    flows = df.groupby(\n",
    "        [location_from, location_to, 'eq_type'], observed=True\n",
    "    )['volume_teu_proposal'].sum()\n",
    "\n",
    "    # Calculate inflow, outflow, and net flow at the location level\n",
    "    location_stats = pd.DataFrame({\n",
    "        'outflow': df.groupby(location_from, observed=True)['volume_teu_proposal'].sum(),\n",
    "        'inflow': df.groupby(location_to, observed=True)['volume_teu_proposal'].sum()\n",
    "    }).fillna(0)  # Fill NaN values with 0 for locations with no inflow or outflow\n",
    "\n",
    "    # Calculate net flow (inflow - outflow) for each location\n",
    "    location_stats['net_flow'] = location_stats['inflow'] - location_stats['outflow']\n",
    "\n",
    "    # Reset index to bring location names into the DataFrame\n",
    "    location_stats = location_stats.reset_index()\n",
    "\n",
    "    # Rename columns to meaningful names\n",
    "    location_stats.columns = ['location', 'outflow', 'inflow', 'net_flow']\n",
    "\n",
    "    return flows, location_stats\n",
    "\n",
    "\n",
    "def calculate_conversion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the conversion rate (actual vs proposed volume) for each source and equipment type.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Preprocessed DataFrame with movement data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated conversion rate for each source and equipment type.\n",
    "    \"\"\"\n",
    "    return df.groupby(['source_flag', 'eq_type'], observed=True).agg({\n",
    "        'volume_teu_proposal': 'sum',\n",
    "        'volume_teu_actual': 'sum'\n",
    "    }).assign(\n",
    "        conversion_rate=lambda x: (x['volume_teu_actual'] / x['volume_teu_proposal'] * 100).fillna(0)\n",
    "    )\n",
    "\n",
    "\n",
    "def find_unused(df: pd.DataFrame, location_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify movements with zero actual volume, aggregating relevant data.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing movement data.\n",
    "        location_type (str): Location type ('locode' or 'subarea') to determine columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated data for unused movements.\n",
    "    \"\"\"\n",
    "    # Make a copy of the input DataFrame to avoid unintended side effects\n",
    "    df = df.copy()\n",
    "\n",
    "    # Dynamically determine the location columns based on location_type\n",
    "    location_from = f\"{location_type}_from\"\n",
    "    location_to = f\"{location_type}_to\"\n",
    "\n",
    "    # Add start and end dates derived from yearweek\n",
    "    df['start_date'] = df['start_yearweek'].apply(yearweek_to_date)\n",
    "    df['end_date'] = df['end_yearweek'].apply(yearweek_to_date)\n",
    "\n",
    "    # Filter for movements with zero actual volume, cancelled status, and positive proposed volume\n",
    "    mask = (df['volume_teu_actual'] == 0) & (df['status'] == 'CL') & (df['volume_teu_proposal'] > 0)\n",
    "\n",
    "    # Aggregate data for unused movements\n",
    "    unused = df[mask].groupby(\n",
    "        [location_from, location_to, 'eq_type', 'mot'], observed=True\n",
    "    ).agg({\n",
    "        'id_number': 'count',\n",
    "        'volume_teu_proposal': ['sum', 'mean'],\n",
    "        'start_date': 'min',\n",
    "        'end_date': 'max'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename and format aggregated columns for readability\n",
    "    unused.columns = [\n",
    "        f\"{col[0]}_{col[1]}\" if col[1] else col[0]\n",
    "        for col in unused.columns\n",
    "    ]\n",
    "    unused['proposal_timespan_days'] = (\n",
    "        unused['end_date_max'] - unused['start_date_min']\n",
    "    ).dt.days\n",
    "    unused = unused.rename(columns={\n",
    "        'eq_type': 'equipment_type',\n",
    "        'mot': 'mode_of_transportation',\n",
    "        'id_number_count': 'unused_count',\n",
    "        'volume_teu_proposal_sum': 'total_volume_proposed',\n",
    "        'volume_teu_proposal_mean': 'avg_volume_proposed',\n",
    "        'start_date_min': 'first_proposed',\n",
    "        'end_date_max': 'last_proposed'\n",
    "    })\n",
    "    \n",
    "    # Sort results by unused count and total proposed volume\n",
    "    return unused.sort_values(\n",
    "        ['unused_count', 'total_volume_proposed'], ascending=[False, False]\n",
    "    )\n",
    "\n",
    "def calculate_metrics(df: pd.DataFrame, location_type: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate various metrics for container movements, including overall stats \n",
    "    and breakdowns by equipment type, source flag, and mode of transport.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Preprocessed DataFrame with movement data.\n",
    "        location_type (str): Location type ('locode' or 'subarea') to determine columns.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing calculated metrics.\n",
    "    \"\"\"\n",
    "    # Dynamically determine the location columns based on location_type\n",
    "    location_from = f\"{location_type}_from\"\n",
    "    location_to = f\"{location_type}_to\"\n",
    "\n",
    "    # Aggregate overall metrics for the entire dataset\n",
    "    overall_metrics = df.agg({\n",
    "        'volume_teu_proposal': 'sum',  # Total proposed volume\n",
    "        'volume_teu_actual': 'sum',   # Total actual volume\n",
    "        'duration_weeks': 'mean'      # Average duration of movements in weeks\n",
    "    })\n",
    "\n",
    "    # Calculate the total number of unique routes\n",
    "    unique_routes = df.groupby(\n",
    "        [location_from, location_to], observed=True\n",
    "    ).ngroups  # Count distinct groups of location pairs\n",
    "\n",
    "    # Compile overall metrics, including conversion rate and total movements\n",
    "    return {\n",
    "        'overall': {\n",
    "            'total_volume_proposed': float(overall_metrics['volume_teu_proposal']),\n",
    "            'total_volume_actual': float(overall_metrics['volume_teu_actual']),\n",
    "            'conversion_rate': float(overall_metrics['volume_teu_actual'] / \n",
    "                                      overall_metrics['volume_teu_proposal'] * 100 \n",
    "                                      if overall_metrics['volume_teu_proposal'] > 0 else 0),\n",
    "            'total_movements': len(df),\n",
    "            'unique_routes': unique_routes,\n",
    "            'avg_duration': float(overall_metrics['duration_weeks'])\n",
    "        },\n",
    "        # Breakdowns by equipment type, source flag, and mode of transport\n",
    "        'equipment': df.groupby('eq_type', observed=True).agg({\n",
    "            'volume_teu_proposal': 'sum',\n",
    "            'volume_teu_actual': 'sum'\n",
    "        }).to_dict(),\n",
    "        'source': df.groupby('source_flag', observed=True).agg({\n",
    "            'volume_teu_proposal': 'sum',\n",
    "            'volume_teu_actual': 'sum'\n",
    "        }).to_dict(),\n",
    "        'transport': df.groupby('mot', observed=True).agg({\n",
    "            'volume_teu_proposal': 'sum',\n",
    "            'volume_teu_actual': 'sum'\n",
    "        }).to_dict()\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_container_movements(\n",
    "    df: pd.DataFrame,\n",
    "    time_window: int = 4,\n",
    "    min_volume: float = 0,\n",
    "    include_cancelled: bool = False,\n",
    "    location_type: str = \"locode\"\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Main function to analyze container movements and produce a comprehensive \n",
    "    set of insights, including flow analysis, unused movements, and metrics.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing container movement data.\n",
    "        time_window (int, optional): Time window for analysis (not used in this implementation).\n",
    "        min_volume (float, optional): Minimum volume threshold for filtering. Default is 0.\n",
    "        include_cancelled (bool, optional): Whether to include cancelled movements. Default is False.\n",
    "        location_type (str, optional): Type of location to analyze ('locode' or 'subarea'). Default is 'locode'.\n",
    "\n",
    "    Returns:\n",
    "        Dict: A dictionary containing results of the analysis, including flows, locations,\n",
    "              conversion rates, unused movements, and overall metrics.\n",
    "    \"\"\"\n",
    "    # Dynamically determine the location columns based on location_type\n",
    "    location_from = f\"{location_type}_from\"\n",
    "    location_to = f\"{location_type}_to\"\n",
    "\n",
    "    # Validate that all required columns are present in the input DataFrame\n",
    "    required_columns = [\n",
    "        'status', 'volume_teu_proposal', 'volume_teu_actual',\n",
    "        'start_yearweek', 'end_yearweek',\n",
    "        location_from, location_to, 'eq_type', 'source_flag', 'mot'\n",
    "    ]\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "    # Step 1: Preprocess the data\n",
    "    processed_df = preprocess_dataframe(df, min_volume, include_cancelled, location_type)\n",
    "    print(\"Preprocessing completed.\")  # Informational log for tracking progress\n",
    "\n",
    "    # Step 2: Perform various analyses\n",
    "    # Analyze flows between locations\n",
    "    flows, locations = analyze_flows(processed_df, location_type)\n",
    "\n",
    "    # Calculate conversion rates for different source flags and equipment types\n",
    "    conversion_rates = calculate_conversion(processed_df)\n",
    "\n",
    "    # Identify and aggregate data for unused movements\n",
    "    unused_actions = find_unused(df, location_type)\n",
    "\n",
    "    # Calculate overall metrics and breakdowns\n",
    "    metrics = calculate_metrics(processed_df, location_type)\n",
    "\n",
    "    print(\"Analysis completed.\")  # Informational log for tracking progress\n",
    "\n",
    "    # Return all analysis results as a dictionary\n",
    "    return {\n",
    "        'flows': flows,                  # Aggregated flows between locations\n",
    "        'locations': locations,          # Inflow, outflow, and net flow stats for locations\n",
    "        'conversion_rates': conversion_rates,  # Conversion rate metrics\n",
    "        'unused_actions': unused_actions,      # Unused movements\n",
    "        'metrics': metrics,              # Overall and breakdown metrics\n",
    "        'original_df': processed_df      # The preprocessed DataFrame for reference\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed.\n",
      "Analysis completed.\n",
      "Preprocessing completed.\n",
      "Analysis completed.\n"
     ]
    }
   ],
   "source": [
    "# analysis on locode level\n",
    "results_locode = analyze_container_movements(\n",
    "    df=dap_with_location,\n",
    "    time_window=4,\n",
    "    min_volume=1,\n",
    "    include_cancelled=False,\n",
    "    location_type=\"locode\"  # Use \"locode_from\" and \"locode_to\"\n",
    ")\n",
    "\n",
    "# analysis on subarea level\n",
    "results_subarea = analyze_container_movements(\n",
    "    df=dap_with_location,\n",
    "    time_window=4,\n",
    "    min_volume=1,\n",
    "    include_cancelled=False,\n",
    "    location_type=\"subarea\"  # Use \"subarea_from\" and \"subarea_to\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "establish regional heirarchies in the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates explicit and clear regional heirachies in the subarea dataframe\n",
    "def extract_clean_locations(df):\n",
    "    \"\"\"\n",
    "    Creates new columns with clean location names from code/name columns.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns:\n",
    "            - region_code/name\n",
    "            - subregion_code/name\n",
    "            - area_code/name\n",
    "            - subarea_code/name\n",
    "            \n",
    "    Returns:\n",
    "        DataFrame with four new columns:\n",
    "            - region\n",
    "            - subregion\n",
    "            - area\n",
    "            - subarea\n",
    "    \"\"\"\n",
    "    def clean_name(value):\n",
    "        \"\"\"\n",
    "        Extracts the name part after '/' and removes any trailing codes.\n",
    "        \n",
    "        Args:\n",
    "            value: String in format 'CODE / NAME'\n",
    "            \n",
    "        Returns:\n",
    "            Clean location name\n",
    "        \"\"\"\n",
    "        # Handle special cases\n",
    "        if any(x in str(value) for x in ['n/a', 'n/r', 'n/u', '???', '!!!', '***']):\n",
    "            return ''\n",
    "            \n",
    "        try:\n",
    "            # Split on '/' and take the name part\n",
    "            name = value.split('/')[1].strip()\n",
    "            return name\n",
    "        except:\n",
    "            return ''\n",
    "    \n",
    "    # Create new columns with clean names\n",
    "    df['region'] = df['region_code/name'].apply(clean_name)\n",
    "    df['subregion'] = df['subregion_code/name'].apply(clean_name)\n",
    "    df['area'] = df['area_code/name'].apply(clean_name)\n",
    "    df['subarea_name'] = df['subarea_code/name'].apply(clean_name)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_code/name</th>\n",
       "      <th>subregion_code/name</th>\n",
       "      <th>area_code/name</th>\n",
       "      <th>subarea_code/name</th>\n",
       "      <th>un_locode</th>\n",
       "      <th>region</th>\n",
       "      <th>subregion</th>\n",
       "      <th>area</th>\n",
       "      <th>subarea_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S / S. EUROPE</td>\n",
       "      <td>SIB / IBERIA</td>\n",
       "      <td>SIBEM / SP MED</td>\n",
       "      <td>SIBEMBCN / BARCELONA</td>\n",
       "      <td>ADALV</td>\n",
       "      <td>S. EUROPE</td>\n",
       "      <td>IBERIA</td>\n",
       "      <td>SP MED</td>\n",
       "      <td>BARCELONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAUH / ABU DHABI</td>\n",
       "      <td>AEAAN</td>\n",
       "      <td>M. EAST</td>\n",
       "      <td>ARAB GULF</td>\n",
       "      <td>EMIRATES</td>\n",
       "      <td>ABU DHABI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAJM / AJMAN</td>\n",
       "      <td>AEAJM</td>\n",
       "      <td>M. EAST</td>\n",
       "      <td>ARAB GULF</td>\n",
       "      <td>EMIRATES</td>\n",
       "      <td>AJMAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEJEA / JEBEL ALI</td>\n",
       "      <td>AEALQ</td>\n",
       "      <td>M. EAST</td>\n",
       "      <td>ARAB GULF</td>\n",
       "      <td>EMIRATES</td>\n",
       "      <td>JEBEL ALI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAG / ARAB GULF</td>\n",
       "      <td>MAGAE / EMIRATES</td>\n",
       "      <td>MAGAEAUH / ABU DHABI</td>\n",
       "      <td>AEAUH</td>\n",
       "      <td>M. EAST</td>\n",
       "      <td>ARAB GULF</td>\n",
       "      <td>EMIRATES</td>\n",
       "      <td>ABU DHABI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16710</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAS / S. AFRICA</td>\n",
       "      <td>MASZA / S. AFRICA</td>\n",
       "      <td>MASZAHRE / HARARE</td>\n",
       "      <td>ZWVFA</td>\n",
       "      <td>M. EAST</td>\n",
       "      <td>S. AFRICA</td>\n",
       "      <td>S. AFRICA</td>\n",
       "      <td>HARARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16711</th>\n",
       "      <td>M / M. EAST</td>\n",
       "      <td>MAS / S. AFRICA</td>\n",
       "      <td>MASZA / S. AFRICA</td>\n",
       "      <td>MASZAHRE / HARARE</td>\n",
       "      <td>ZWWKI</td>\n",
       "      <td>M. EAST</td>\n",
       "      <td>S. AFRICA</td>\n",
       "      <td>S. AFRICA</td>\n",
       "      <td>HARARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16712</th>\n",
       "      <td>? / n/a</td>\n",
       "      <td>??? / n/a</td>\n",
       "      <td>????? / n/a</td>\n",
       "      <td>???????? / n/a</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16713</th>\n",
       "      <td>! / n/r</td>\n",
       "      <td>!!! / n/r</td>\n",
       "      <td>!!!!! / n/r</td>\n",
       "      <td>!!!!!!!! / n/r</td>\n",
       "      <td>n/r</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>* / n/u</td>\n",
       "      <td>*** / n/u</td>\n",
       "      <td>***** / n/u</td>\n",
       "      <td>******** / n/u</td>\n",
       "      <td>n/u</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16715 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      region_code/name subregion_code/name     area_code/name  \\\n",
       "0        S / S. EUROPE        SIB / IBERIA     SIBEM / SP MED   \n",
       "1          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "2          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "3          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "4          M / M. EAST     MAG / ARAB GULF   MAGAE / EMIRATES   \n",
       "...                ...                 ...                ...   \n",
       "16710      M / M. EAST     MAS / S. AFRICA  MASZA / S. AFRICA   \n",
       "16711      M / M. EAST     MAS / S. AFRICA  MASZA / S. AFRICA   \n",
       "16712          ? / n/a           ??? / n/a        ????? / n/a   \n",
       "16713          ! / n/r           !!! / n/r        !!!!! / n/r   \n",
       "16714          * / n/u           *** / n/u        ***** / n/u   \n",
       "\n",
       "          subarea_code/name un_locode     region  subregion       area  \\\n",
       "0      SIBEMBCN / BARCELONA     ADALV  S. EUROPE     IBERIA     SP MED   \n",
       "1      MAGAEAUH / ABU DHABI     AEAAN    M. EAST  ARAB GULF   EMIRATES   \n",
       "2          MAGAEAJM / AJMAN     AEAJM    M. EAST  ARAB GULF   EMIRATES   \n",
       "3      MAGAEJEA / JEBEL ALI     AEALQ    M. EAST  ARAB GULF   EMIRATES   \n",
       "4      MAGAEAUH / ABU DHABI     AEAUH    M. EAST  ARAB GULF   EMIRATES   \n",
       "...                     ...       ...        ...        ...        ...   \n",
       "16710     MASZAHRE / HARARE     ZWVFA    M. EAST  S. AFRICA  S. AFRICA   \n",
       "16711     MASZAHRE / HARARE     ZWWKI    M. EAST  S. AFRICA  S. AFRICA   \n",
       "16712        ???????? / n/a       NaN                                    \n",
       "16713        !!!!!!!! / n/r       n/r                                    \n",
       "16714        ******** / n/u       n/u                                    \n",
       "\n",
       "      subarea_name  \n",
       "0        BARCELONA  \n",
       "1        ABU DHABI  \n",
       "2            AJMAN  \n",
       "3        JEBEL ALI  \n",
       "4        ABU DHABI  \n",
       "...            ...  \n",
       "16710       HARARE  \n",
       "16711       HARARE  \n",
       "16712               \n",
       "16713               \n",
       "16714               \n",
       "\n",
       "[16715 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subarea_cleaned = extract_clean_locations(subarea_cleaned)\n",
    "subarea_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flows\n",
    "df_subarea_flows = results_subarea['flows'].reset_index()\n",
    "df_locode_flows = results_locode['flows'].reset_index()\n",
    "\n",
    "#locations\n",
    "df_subarea_locations = results_subarea['locations']\n",
    "df_locode_locations = results_locode['locations']\n",
    "\n",
    "#conversion_rates\n",
    "df_subarea_conversion_rates = results_subarea['conversion_rates'].reset_index()\n",
    "df_locode_conversion_rates = results_locode['conversion_rates'].reset_index()\n",
    "\n",
    "#unused_actions\n",
    "df_subarea_unused_actions = results_subarea['unused_actions']\n",
    "df_locode_unused_actions = results_locode['unused_actions']\n",
    "\n",
    "#metrics\n",
    "dict_subarea_metrics = results_subarea['metrics']\n",
    "dict_locode_metrics = results_locode['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for merging output data with location data\n",
    "def merge_location_flows(df_flows, subarea_mapping, location_type='locode'):\n",
    "    \"\"\"\n",
    "    Merge flow data with subarea mapping and geographic information, handling multiple data formats.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_flows : DataFrame\n",
    "        Can handle different flow data formats:\n",
    "        1. Single location column with flows:\n",
    "           - columns: ['location', 'outflow', 'inflow', 'net_flow']\n",
    "        2. From/To pairs with volume:\n",
    "           - for locodes: ['locode_from', 'locode_to', 'eq_type', 'volume_teu_proposal']\n",
    "           - for subareas: ['subarea_from', 'subarea_to', 'eq_type', 'volume_teu_proposal']\n",
    "    \n",
    "    subarea_mapping : DataFrame\n",
    "        Reference mapping with columns:\n",
    "        - 'un_locode': port/location code\n",
    "        - 'subarea_code/name': format \"CODE / NAME\" (e.g., \"MAGAEAJM / AJMAN\")\n",
    "        - geography columns: 'region', 'subregion', 'area'\n",
    "    \n",
    "    location_type : str\n",
    "        Specifies the type of location identifiers in df_flows:\n",
    "        - 'locode': for UN LOCODE format (e.g., 'AEAJM')\n",
    "        - 'subarea': for subarea code format (e.g., 'MAGAEAJM')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added geographic information, maintaining original identifiers\n",
    "    and adding mapped codes where applicable.\n",
    "    \"\"\"\n",
    "    # Create clean mappings\n",
    "    locode_to_subarea = subarea_mapping[['un_locode', 'subarea_code/name']].drop_duplicates()\n",
    "    locode_to_subarea['subarea_code'] = locode_to_subarea['subarea_code/name'].str.split(' / ').str[0]\n",
    "    \n",
    "    # Create geography mapping\n",
    "    subarea_code_to_geo = subarea_mapping[['subarea_code/name', 'region', 'subregion', 'area']].drop_duplicates()\n",
    "    subarea_code_to_geo['subarea_code'] = subarea_code_to_geo['subarea_code/name'].str.split(' / ').str[0]\n",
    "    subarea_code_to_geo = subarea_code_to_geo.drop('subarea_code/name', axis=1)\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    result = df_flows.copy()\n",
    "    \n",
    "    # Detect data format based on columns\n",
    "    has_location = 'location' in result.columns\n",
    "    has_subarea_pairs = 'subarea_from' in result.columns and 'subarea_to' in result.columns\n",
    "    has_locode_pairs = 'locode_from' in result.columns and 'locode_to' in result.columns\n",
    "    \n",
    "    if has_location:\n",
    "        # Handle single location column format\n",
    "        if location_type.lower() == 'locode':\n",
    "            # Convert locode to subarea code\n",
    "            result = result.merge(\n",
    "                locode_to_subarea[['un_locode', 'subarea_code']],\n",
    "                left_on='location',\n",
    "                right_on='un_locode',\n",
    "                how='left'\n",
    "            ).rename(columns={\n",
    "                'location': 'locode',\n",
    "                'subarea_code': 'subarea'\n",
    "            }).drop('un_locode', axis=1)\n",
    "            \n",
    "            # Add geographic information\n",
    "            result = result.merge(\n",
    "                subarea_code_to_geo[['subarea_code', 'region', 'subregion', 'area']],\n",
    "                left_on='subarea',\n",
    "                right_on='subarea_code',\n",
    "                how='left'\n",
    "            ).drop('subarea_code', axis=1)\n",
    "            \n",
    "        else:  # subarea type\n",
    "            result = result.rename(columns={'location': 'subarea'})\n",
    "            \n",
    "            # Add geographic information\n",
    "            result = result.merge(\n",
    "                subarea_code_to_geo[['subarea_code', 'region', 'subregion', 'area']],\n",
    "                left_on='subarea',\n",
    "                right_on='subarea_code',\n",
    "                how='left'\n",
    "            ).drop('subarea_code', axis=1)\n",
    "            \n",
    "    elif has_subarea_pairs or has_locode_pairs:\n",
    "        if has_locode_pairs:\n",
    "            # First merge: origin\n",
    "            result = result.merge(\n",
    "                locode_to_subarea[['un_locode', 'subarea_code']],\n",
    "                left_on='locode_from',\n",
    "                right_on='un_locode',\n",
    "                how='left'\n",
    "            ).rename(columns={'subarea_code': 'subarea_from'}).drop('un_locode', axis=1)\n",
    "            \n",
    "            # Second merge: destination\n",
    "            result = result.merge(\n",
    "                locode_to_subarea[['un_locode', 'subarea_code']],\n",
    "                left_on='locode_to',\n",
    "                right_on='un_locode',\n",
    "                how='left'\n",
    "            ).rename(columns={'subarea_code': 'subarea_to'}).drop('un_locode', axis=1)\n",
    "        \n",
    "        # Add geographic information for origin\n",
    "        result = result.merge(\n",
    "            subarea_code_to_geo[['subarea_code', 'region', 'subregion', 'area']],\n",
    "            left_on='subarea_from',\n",
    "            right_on='subarea_code',\n",
    "            how='left'\n",
    "        ).drop('subarea_code', axis=1)\n",
    "        \n",
    "        # Add geographic information for destination\n",
    "        result = result.merge(\n",
    "            subarea_code_to_geo[['subarea_code', 'region', 'subregion', 'area']],\n",
    "            left_on='subarea_to',\n",
    "            right_on='subarea_code',\n",
    "            how='left',\n",
    "            suffixes=('_from', '_to')\n",
    "        ).drop('subarea_code', axis=1)\n",
    "    \n",
    "    # Drop any remaining unnecessary columns\n",
    "    cols_to_drop = [col for col in result.columns if col.startswith('subarea_code/name')]\n",
    "    result = result.drop(cols_to_drop, axis=1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>outflow</th>\n",
       "      <th>inflow</th>\n",
       "      <th>net_flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AEAJM</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEAUH</td>\n",
       "      <td>5969.0</td>\n",
       "      <td>13152.0</td>\n",
       "      <td>7183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEJEA</td>\n",
       "      <td>52058.0</td>\n",
       "      <td>5657.0</td>\n",
       "      <td>-46401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AESHJ</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1725.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALDRZ</td>\n",
       "      <td>651.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>ZACPT</td>\n",
       "      <td>191.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ZADUR</td>\n",
       "      <td>1577.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>-1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>ZAPLZ</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>ZAPTN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>ZAZBA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    location  outflow   inflow  net_flow\n",
       "0      AEAJM    500.0      0.0    -500.0\n",
       "1      AEAUH   5969.0  13152.0    7183.0\n",
       "2      AEJEA  52058.0   5657.0  -46401.0\n",
       "3      AESHJ   1725.0      0.0   -1725.0\n",
       "4      ALDRZ    651.0      0.0    -651.0\n",
       "..       ...      ...      ...       ...\n",
       "547    ZACPT    191.0    452.0     261.0\n",
       "548    ZADUR   1577.0    501.0   -1076.0\n",
       "549    ZAPLZ    383.0      0.0    -383.0\n",
       "550    ZAPTN     20.0      0.0     -20.0\n",
       "551    ZAZBA      0.0     20.0      20.0\n",
       "\n",
       "[552 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locode_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(df_subarea_flows): 5914, len(df_locode_flows): 6579\n",
      "ic| len(flows_subarea): 5914, len(flows_locode): 6579\n",
      "ic| len(df_subarea_locations): 376, len(df_locode_locations): 552\n",
      "ic| len(locations_subarea): 376, len(locations_locode): 552\n",
      "ic| len(df_subarea_unused_actions): 16391\n",
      "    len(df_locode_unused_actions): 17654\n",
      "ic| len(unused_actions_subarea): 16391\n",
      "    len(unused_actions_locode): 17654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16391, 17654)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#establishing location heirarchies\n",
    "# For subarea-based flows:\n",
    "flows_subarea = merge_location_flows(df_subarea_flows, subarea_cleaned, location_type='subarea')\n",
    "# For locode-based flows:\n",
    "flows_locode = merge_location_flows(df_locode_flows, subarea_cleaned, location_type='locode')\n",
    "ic(len(df_subarea_flows), len(df_locode_flows))\n",
    "ic(len(flows_subarea), len(flows_locode))\n",
    "\n",
    "# For subarea-based locations:\n",
    "locations_subarea = merge_location_flows(df_subarea_locations, subarea_cleaned, location_type='subarea')\n",
    "# For locode-based locations:\n",
    "locations_locode = merge_location_flows(df_locode_locations, subarea_cleaned, location_type='locode')\n",
    "ic(len(df_subarea_locations), len(df_locode_locations))\n",
    "ic(len(locations_subarea), len(locations_locode))\n",
    "\n",
    "# For subarea-based unused_actions:\n",
    "unused_actions_subarea = merge_location_flows(df_subarea_unused_actions, subarea_cleaned, location_type='subarea')\n",
    "# For locode-based unused_actions:\n",
    "unused_actions_locode = merge_location_flows(df_locode_unused_actions, subarea_cleaned, location_type='locode')\n",
    "ic(len(df_subarea_unused_actions), len(df_locode_unused_actions))\n",
    "ic(len(unused_actions_subarea), len(unused_actions_locode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Save data to output for safekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #flows\n",
    "# flows_subarea.to_csv('flows_subarea.csv', index=False)\n",
    "# flows_locode.to_csv('flows_locode.csv', index=False)\n",
    "\n",
    "# #locations\n",
    "# locations_subarea.to_csv('locations_subarea.csv', index=False)\n",
    "# locations_locode.to_csv('locations_locode.csv', index=False)\n",
    "\n",
    "# #conversion_rates\n",
    "# df_subarea_conversion_rates.to_csv('conversion_rates_subarea.csv', index=False)\n",
    "# df_locode_conversion_rates.to_csv('conversion_rates_locode.csv', index=False)\n",
    "\n",
    "# #unused_actions\n",
    "# unused_actions_subarea.to_csv('unused_actions_subarea.csv', index=False)\n",
    "# unused_actions_locode.to_csv('unused_actions_locode.csv', index=False)\n",
    "\n",
    "# #metrics\n",
    "# with open('metrics_subarea.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(dict_subarea_metrics, f, indent=2)\n",
    "\n",
    "# with open('metrics_locode.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(dict_locode_metrics, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for detecting circular movements\n",
    "def detect_circular_movements(df: pd.DataFrame, min_cycle_length=3, max_cycle_length=5, window_weeks=4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect circular container movements using NetworkX within a given time window.\n",
    "\n",
    "    This function analyzes movements per equipment type and detects cycles in the movement graph.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame containing movement data.\n",
    "    - min_cycle_length (int): Minimum unique locations required to form a valid cycle.\n",
    "    - max_cycle_length (int): Maximum unique locations allowed in a cycle.\n",
    "    - window_weeks (int): Time window (in weeks) within which cycles are analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with detected circular movements and their details.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep only movements with status 'BK' (Booked)\n",
    "    df = df[df['status'] == 'BK'].copy()\n",
    "\n",
    "    # List to store detected cycle details\n",
    "    detailed_cycles = []\n",
    "\n",
    "    # Process each equipment type separately\n",
    "    print(\"Analyzing by equipment type...\")\n",
    "    for eq_type in tqdm(df['eq_type'].unique()):  # Iterate over each unique equipment type\n",
    "        eq_df = df[df['eq_type'] == eq_type]  # Filter dataset for this equipment type\n",
    "\n",
    "        # Analyze movements within each time window\n",
    "        for start_week in eq_df['start_yearweek'].unique():\n",
    "            end_week = start_week + window_weeks  # Define the end of the window\n",
    "\n",
    "            # Select movements that occur within the defined time window\n",
    "            window_df = eq_df[\n",
    "                (eq_df['start_yearweek'] >= start_week) & \n",
    "                (eq_df['start_yearweek'] < end_week)\n",
    "            ]\n",
    "\n",
    "            # Skip processing if the window has too few movements to form a cycle\n",
    "            if len(window_df) < min_cycle_length:\n",
    "                continue\n",
    "\n",
    "            # Create a directed graph where nodes are locations and edges represent movements\n",
    "            G = nx.DiGraph()\n",
    "\n",
    "            # Add edges (movements) to the graph\n",
    "            for _, row in window_df.iterrows():\n",
    "                G.add_edge(\n",
    "                    row['locode_from'],  # Starting location\n",
    "                    row['locode_to'],    # Destination location\n",
    "                    id=row['id_number'],  # Movement ID\n",
    "                    week=row['start_yearweek'],  # Start week of movement\n",
    "                    volume=row['volume_teu_proposal'],  # Movement volume\n",
    "                    mot=row['mot']  # Mode of transport\n",
    "                )\n",
    "\n",
    "            # Detect cycles in the graph\n",
    "            try:\n",
    "                cycles = list(nx.simple_cycles(G))  # Extract all cycles\n",
    "                \n",
    "                # Process each detected cycle\n",
    "                for cycle in cycles:\n",
    "                    # Ensure cycle length is within valid range\n",
    "                    if min_cycle_length <= len(set(cycle)) <= max_cycle_length:\n",
    "                        cycle_moves = []  # Stores movement details forming the cycle\n",
    "                        total_volume = 0  # Tracks total volume of cycle movements\n",
    "                        movement_ids = []  # Stores movement IDs\n",
    "                        transport_modes = []  # Tracks transport modes\n",
    "\n",
    "                        valid_cycle = True  # Flag to check if the cycle is complete\n",
    "\n",
    "                        # Verify each movement exists in the dataset\n",
    "                        for i in range(len(cycle)):\n",
    "                            from_loc = cycle[i]  # Current location\n",
    "                            to_loc = cycle[(i+1) % len(cycle)]  # Next location in cycle\n",
    "\n",
    "                            # Find movements matching this step in the cycle\n",
    "                            moves = window_df[\n",
    "                                (window_df['locode_from'] == from_loc) &\n",
    "                                (window_df['locode_to'] == to_loc)\n",
    "                            ]\n",
    "\n",
    "                            # If any step in the cycle is missing, discard this cycle\n",
    "                            if moves.empty:\n",
    "                                valid_cycle = False\n",
    "                                break\n",
    "\n",
    "                            # Aggregate movement details\n",
    "                            total_volume += moves['volume_teu_proposal'].sum()\n",
    "                            movement_ids.extend(moves['id_number'].tolist())\n",
    "                            transport_modes.extend(moves['mot'].tolist())\n",
    "                            cycle_moves.extend(moves.to_dict('records'))\n",
    "\n",
    "                        # Save valid cycle details\n",
    "                        if valid_cycle:\n",
    "                            detailed_cycles.append({\n",
    "                                'cycle_path': ' -> '.join(cycle + [cycle[0]]),  # Full cycle path\n",
    "                                'eq_type': eq_type,  # Equipment type\n",
    "                                'start_yearweek': start_week,  # Start week\n",
    "                                'total_volume': total_volume,  # Total TEU volume in cycle\n",
    "                                'movement_count': len(cycle_moves),  # Number of movements in cycle\n",
    "                                'movement_ids': movement_ids,  # List of movement IDs\n",
    "                                'transport_modes': transport_modes,  # Transport modes used\n",
    "                                'locations': cycle  # List of locations forming the cycle\n",
    "                            })\n",
    "\n",
    "            except nx.NetworkXError:\n",
    "                # If graph analysis fails, skip this window\n",
    "                continue\n",
    "\n",
    "    # Convert detected cycle list into a DataFrame and return\n",
    "    return pd.DataFrame(detailed_cycles)\n",
    "\n",
    "def visualize_movement_graph(df, top_n=100):\n",
    "    \"\"\"\n",
    "    Generate a visual representation of container movements.\n",
    "\n",
    "    This function creates a directed graph where nodes represent locations and edges represent container movements.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing movement data.\n",
    "    - top_n (int): Number of most frequent locations to visualize.\n",
    "\n",
    "    Saves:\n",
    "    - A PNG file ('movement_network.png') showing the network visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Compute movement frequency per location\n",
    "    location_freq = pd.concat([\n",
    "        df['locode_from'].value_counts(), \n",
    "        df['locode_to'].value_counts()\n",
    "    ]).groupby(level=0).sum()\n",
    "\n",
    "    # Select the top N most active locations\n",
    "    top_locations = set(location_freq.nlargest(top_n).index)\n",
    "\n",
    "    # Add edges for selected locations\n",
    "    print(\"Building network graph...\")\n",
    "    for _, row in tqdm(df[\n",
    "        df['locode_from'].isin(top_locations) & \n",
    "        df['locode_to'].isin(top_locations)\n",
    "    ].iterrows()):\n",
    "        G.add_edge(row['locode_from'], row['locode_to'], \n",
    "                   weight=row['volume_teu_proposal'])\n",
    "\n",
    "    # Generate visualization\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "\n",
    "    # Draw nodes (locations)\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=100, node_color='lightblue')\n",
    "\n",
    "    # Draw edges (movements)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, width=0.5, alpha=0.6)\n",
    "\n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "\n",
    "    # Save graph visualization\n",
    "    plt.title(\"Container Movement Network\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('movement_network.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def circles(df, sample_size=None):\n",
    "    \"\"\"\n",
    "    Main function to execute circular movement detection and visualization.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The dataset containing movement records.\n",
    "    - sample_size (int, optional): Number of rows to sample from the dataset for faster processing.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing detected circular movements.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    print(\"Loading data...\")\n",
    "    df = df.copy()\n",
    "\n",
    "    # Sample dataset if required\n",
    "    if sample_size:\n",
    "        df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    # Detect circular movements\n",
    "    print(f\"\\nAnalyzing {len(df)} movements...\")\n",
    "    circular_movements = detect_circular_movements(df)\n",
    "\n",
    "    # Display and save results\n",
    "    print(\"\\nCircular Movement Analysis:\")\n",
    "    print(f\"Total circular movements found: {len(circular_movements)}\")\n",
    "\n",
    "    if not circular_movements.empty:\n",
    "        print(\"\\nSample Circular Movements:\")\n",
    "        print(circular_movements.head())\n",
    "\n",
    "        print(\"\\nCircular Movements by Equipment Type:\")\n",
    "        print(circular_movements.groupby('eq_type').size())\n",
    "\n",
    "        # Save detected cycles\n",
    "        print(\"output saved as csv\")\n",
    "        circular_movements.to_csv('networkx_circular_movements.csv', index=False)\n",
    "\n",
    "        # Generate visualization\n",
    "        visualize_movement_graph(df)\n",
    "    else:\n",
    "        print(\"No circular movements found.\")\n",
    "\n",
    "    return circular_movements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Analyzing 242097 movements...\n",
      "Analyzing by equipment type...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:45<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Circular Movement Analysis:\n",
      "Total circular movements found: 3198\n",
      "\n",
      "Sample Circular Movements:\n",
      "                                  cycle_path eq_type  start_yearweek  \\\n",
      "0           USPDX -> USTIW -> USSEA -> USPDX    20GE          202401   \n",
      "1           USPDX -> USSEA -> USTIW -> USPDX    20GE          202401   \n",
      "2  CATOR -> CAMTR -> CAEDM -> CAVAN -> CATOR    20GE          202401   \n",
      "3  CATOR -> CAMTR -> USMES -> CAVAN -> CATOR    20GE          202401   \n",
      "4  CATOR -> CAMTR -> USDET -> CAVAN -> CATOR    20GE          202401   \n",
      "\n",
      "   total_volume  movement_count  \\\n",
      "0             0               8   \n",
      "1             0               7   \n",
      "2             0              19   \n",
      "3             0              17   \n",
      "4             0              17   \n",
      "\n",
      "                                        movement_ids  \\\n",
      "0  [7804779, 7827912, 7829279, 7830749, 7830009, ...   \n",
      "1  [7807841, 7850927, 7851492, 7808927, 7830022, ...   \n",
      "2  [7790652, 7791480, 7792319, 7792320, 7792321, ...   \n",
      "3  [7790652, 7791480, 7792319, 7792320, 7792321, ...   \n",
      "4  [7790652, 7791480, 7792319, 7792320, 7792321, ...   \n",
      "\n",
      "                                     transport_modes  \\\n",
      "0                   [TR, TR, TR, TR, TR, TR, MX, MX]   \n",
      "1                       [RA, TR, RA, TR, TR, TR, TR]   \n",
      "2  [RA, TR, RA, RA, RA, RA, RA, RA, RA, RA, RA, T...   \n",
      "3  [RA, TR, RA, RA, RA, RA, RA, RA, RA, RA, RA, T...   \n",
      "4  [RA, TR, RA, RA, RA, RA, RA, RA, RA, RA, RA, T...   \n",
      "\n",
      "                      locations  \n",
      "0         [USPDX, USTIW, USSEA]  \n",
      "1         [USPDX, USSEA, USTIW]  \n",
      "2  [CATOR, CAMTR, CAEDM, CAVAN]  \n",
      "3  [CATOR, CAMTR, USMES, CAVAN]  \n",
      "4  [CATOR, CAMTR, USDET, CAVAN]  \n",
      "\n",
      "Circular Movements by Equipment Type:\n",
      "eq_type\n",
      "20GE    1188\n",
      "20OT       3\n",
      "20RE       2\n",
      "40FL     276\n",
      "40GE      70\n",
      "40HC     779\n",
      "40OT       5\n",
      "40RE     875\n",
      "dtype: int64\n",
      "Building network graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91745it [00:04, 21041.95it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = pd.read_csv('cleaned_hplld_data.csv')\n",
    "# detect circular movements in booked container routes:\n",
    "circular_movements = circles(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for detecting inefficient routing\n",
    "def yearweek_to_date(yearweek: int) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Convert a yearweek integer (YYYYWW) into a Pandas Timestamp representing the start of that week.\n",
    "\n",
    "    Parameters:\n",
    "    - yearweek (int): The yearweek value (e.g., 202401 for the first week of 2024).\n",
    "\n",
    "    Returns:\n",
    "    - pd.Timestamp: The corresponding date (Monday of that week).\n",
    "    \"\"\"\n",
    "    year = int(str(yearweek)[:4])  # Extract the year (first 4 digits)\n",
    "    week = int(str(yearweek)[4:])  # Extract the week number (last 2 digits)\n",
    "    return pd.to_datetime(f\"{year}-W{week:02d}-1\", format=\"%Y-W%W-%w\")  # Convert to Monday of that week\n",
    "\n",
    "def detect_routing_inefficiencies_optimized(df: pd.DataFrame, window_weeks=4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect inefficient routing patterns in container movements using graph analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The dataset containing movement records.\n",
    "    - window_weeks (int): The time window (in weeks) used to analyze routes.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with identified inefficient routes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter out only booked movements\n",
    "    df = df[df['status'] == 'BK'].copy()\n",
    "\n",
    "    # List to store inefficient route details\n",
    "    inefficient_routes = []\n",
    "\n",
    "    # Process movements per equipment type\n",
    "    print(\"Analyzing by equipment type...\")\n",
    "    for eq_type in tqdm(df['eq_type'].unique()):  # Iterate over each unique equipment type\n",
    "        eq_df = df[df['eq_type'] == eq_type]  # Filter dataset for the current equipment type\n",
    "\n",
    "        # Analyze movements within each time window\n",
    "        for start_week in eq_df['start_yearweek'].unique():\n",
    "            end_week = start_week + window_weeks  # Define the end of the window\n",
    "\n",
    "            # Select movements that occur within the defined time window\n",
    "            window_df = eq_df[\n",
    "                (eq_df['start_yearweek'] >= start_week) & \n",
    "                (eq_df['start_yearweek'] < end_week)\n",
    "            ]\n",
    "\n",
    "            # Skip analysis if there are not enough movements\n",
    "            if len(window_df) < 2:\n",
    "                continue\n",
    "\n",
    "            # Create a directed graph where nodes are locations and edges represent movements\n",
    "            G = nx.DiGraph()\n",
    "\n",
    "            # Aggregate movement details for the given time window\n",
    "            actual_routes = window_df.groupby(['locode_from', 'locode_to']).agg({\n",
    "                'volume_teu_proposal': 'sum',  # Sum total TEU volume per route\n",
    "                'id_number': list,  # Collect movement IDs\n",
    "                'mot': list,  # Collect modes of transport\n",
    "                'start_yearweek': list  # Collect weeks of movements\n",
    "            }).reset_index()\n",
    "\n",
    "            # Add edges (movements) to the graph\n",
    "            for _, row in actual_routes.iterrows():\n",
    "                G.add_edge(\n",
    "                    row['locode_from'],  # Starting location\n",
    "                    row['locode_to'],    # Destination location\n",
    "                    volume=row['volume_teu_proposal']  # Movement volume\n",
    "                )\n",
    "\n",
    "            # Check each actual route for inefficiencies\n",
    "            for _, route in actual_routes.iterrows():\n",
    "                source = route['locode_from']\n",
    "                target = route['locode_to']\n",
    "\n",
    "                try:\n",
    "                    # Find the shortest path between the source and target\n",
    "                    shortest_path = nx.shortest_path(G, source, target)\n",
    "                    shortest_len = len(shortest_path)\n",
    "\n",
    "                    # Define a cutoff for what is considered an inefficient route\n",
    "                    cutoff = min(shortest_len * 2, shortest_len + 5)\n",
    "\n",
    "                    # Find all paths within the cutoff limit\n",
    "                    actual_paths = list(nx.all_simple_paths(G, source, target, cutoff=cutoff))\n",
    "\n",
    "                    # Evaluate each actual path for inefficiencies\n",
    "                    for path in actual_paths:\n",
    "                        if len(path) > shortest_len:  # The path is inefficient if longer than the shortest path\n",
    "                            path_moves = []  # List to store movement details for this path\n",
    "                            path_volume = float('inf')  # Minimum volume constraint\n",
    "\n",
    "                            # Check if all steps in the path exist in the dataset\n",
    "                            for i in range(len(path) - 1):\n",
    "                                moves = window_df[\n",
    "                                    (window_df['locode_from'] == path[i]) &\n",
    "                                    (window_df['locode_to'] == path[i+1])\n",
    "                                ]\n",
    "                                if moves.empty:\n",
    "                                    path_volume = 0  # If a segment is missing, discard the path\n",
    "                                    break\n",
    "                                path_moves.extend(moves.to_dict('records'))\n",
    "                                path_volume = min(path_volume, moves['volume_teu_proposal'].sum())\n",
    "\n",
    "                            # Save inefficient path details if valid\n",
    "                            if path_volume > 0:\n",
    "                                inefficient_routes.append({\n",
    "                                    'eq_type': eq_type,\n",
    "                                    'start_yearweek': start_week,\n",
    "                                    'start_date': yearweek_to_date(start_week),\n",
    "                                    'from_location': source,\n",
    "                                    'to_location': target,\n",
    "                                    'optimal_path': ' -> '.join(shortest_path),\n",
    "                                    'actual_path': ' -> '.join(path),\n",
    "                                    'volume': path_volume,\n",
    "                                    'movement_ids': route['id_number'],\n",
    "                                    'transport_modes': route['mot'],\n",
    "                                    'weeks': route['start_yearweek'],\n",
    "                                    'extra_stops': len(path) - shortest_len\n",
    "                                })\n",
    "\n",
    "                except nx.NetworkXNoPath:\n",
    "                    continue  # Skip if no path exists\n",
    "\n",
    "    return pd.DataFrame(inefficient_routes)\n",
    "\n",
    "def visualize_movement_graph(df, top_n=100):\n",
    "    \"\"\"\n",
    "    Generate a visual representation of container movements as a network graph.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The dataset containing movement records.\n",
    "    - top_n (int): The number of most frequent locations to visualize.\n",
    "\n",
    "    Saves:\n",
    "    - A PNG file ('movement_network.png') showing the network visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Compute movement frequency per location\n",
    "    location_freq = pd.concat([\n",
    "        df['locode_from'].value_counts(), \n",
    "        df['locode_to'].value_counts()\n",
    "    ]).groupby(level=0).sum()\n",
    "\n",
    "    # Select the top N most active locations\n",
    "    top_locations = set(location_freq.nlargest(top_n).index)\n",
    "\n",
    "    # Add edges for selected locations\n",
    "    print(\"Building network graph...\")\n",
    "    for _, row in tqdm(df[\n",
    "        df['locode_from'].isin(top_locations) & \n",
    "        df['locode_to'].isin(top_locations)\n",
    "    ].iterrows()):\n",
    "        G.add_edge(row['locode_from'], row['locode_to'], \n",
    "                   weight=row['volume_teu_proposal'])\n",
    "\n",
    "    # Generate visualization\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "\n",
    "    # Draw nodes (locations)\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=100, node_color='lightblue')\n",
    "\n",
    "    # Draw edges (movements)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, width=0.5, alpha=0.6)\n",
    "\n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "\n",
    "    # Save graph visualization\n",
    "    plt.title(\"Container Movement Network\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('movement_network.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def inefficient(df):\n",
    "    \"\"\"\n",
    "    Main function to analyze routing inefficiencies in container movements.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The dataset containing movement records.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with detected routing inefficiencies.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Starting analysis...\")\n",
    "    print(f\"Total movements: {len(df)}\")\n",
    "\n",
    "    # Count unique routes\n",
    "    total_routes = df.groupby(['locode_from', 'locode_to']).size().shape[0]\n",
    "    print(f\"Total unique routes: {total_routes}\")\n",
    "\n",
    "    # Detect inefficient routes\n",
    "    print(\"\\nAnalyzing inefficient routes...\")\n",
    "    inefficient_routes = detect_routing_inefficiencies_optimized(df)\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nRouting Inefficiency Analysis:\")\n",
    "    print(f\"Total inefficient routes found: {len(inefficient_routes)}\")\n",
    "\n",
    "    if not inefficient_routes.empty:\n",
    "        print(\"\\nSample Inefficient Routes:\")\n",
    "        print(inefficient_routes.head())\n",
    "\n",
    "        # Save results\n",
    "        print(\"output saved as csv\")\n",
    "        inefficient_routes.to_csv('routing_inefficiencies.csv', index=False)\n",
    "\n",
    "        # Generate visualization\n",
    "        print(\"\\nCreating network visualization...\")\n",
    "        visualize_movement_graph(df)\n",
    "\n",
    "    return inefficient_routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis...\n",
      "Total movements: 242097\n",
      "Total unique routes: 10202\n",
      "\n",
      "Analyzing inefficient routes...\n",
      "Analyzing by equipment type...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [09:00<00:00, 36.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Routing Inefficiency Analysis:\n",
      "Total inefficient routes found: 4612\n",
      "\n",
      "Sample Inefficient Routes:\n",
      "  eq_type  start_yearweek start_date from_location to_location  \\\n",
      "0    20GE          202401 2024-01-01         CLSAI       CLVAP   \n",
      "1    20GE          202401 2024-01-01         CLSAI       CLVAP   \n",
      "2    20GE          202401 2024-01-01         CLSAI       CNSHK   \n",
      "3    20GE          202401 2024-01-01         CNHUA       CNGOM   \n",
      "4    20GE          202401 2024-01-01         CNHUA       CNJMN   \n",
      "\n",
      "     optimal_path                       actual_path  volume  \\\n",
      "0  CLSAI -> CLVAP           CLSAI -> CNSHK -> CLVAP       5   \n",
      "1  CLSAI -> CLVAP  CLSAI -> KRPUS -> CNSHK -> CLVAP       5   \n",
      "2  CLSAI -> CNSHK           CLSAI -> KRPUS -> CNSHK       6   \n",
      "3  CNHUA -> CNGOM  CNHUA -> CNZQG -> HKHKG -> CNGOM       8   \n",
      "4  CNHUA -> CNJMN  CNHUA -> CNZQG -> CNSHK -> CNJMN       2   \n",
      "\n",
      "                                        movement_ids  \\\n",
      "0  [7801282, 7809455, 7830002, 7830024, 7830073, ...   \n",
      "1  [7801282, 7809455, 7830002, 7830024, 7830073, ...   \n",
      "2               [7810215, 7810217, 7810216, 7830112]   \n",
      "3                                          [7808128]   \n",
      "4                                 [7810547, 7774422]   \n",
      "\n",
      "                                     transport_modes  \\\n",
      "0  [TR, TR, TR, TR, TR, TR, TR, TR, TR, TR, TR, T...   \n",
      "1  [TR, TR, TR, TR, TR, TR, TR, TR, TR, TR, TR, T...   \n",
      "2                                   [MX, MX, MX, MX]   \n",
      "3                                               [VE]   \n",
      "4                                           [VE, VE]   \n",
      "\n",
      "                                               weeks  extra_stops  \n",
      "0  [202402, 202402, 202403, 202403, 202403, 20240...            1  \n",
      "1  [202402, 202402, 202403, 202403, 202403, 20240...            2  \n",
      "2                   [202403, 202403, 202403, 202403]            1  \n",
      "3                                           [202402]            2  \n",
      "4                                   [202403, 202401]            2  \n",
      "\n",
      "Creating network visualization...\n",
      "Building network graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91745it [00:04, 20811.74it/s]\n"
     ]
    }
   ],
   "source": [
    "inefficient_routes = inefficient(cleaned_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hapag_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
